"""
Backend Service Fixed - Rapports longs sans erreurs
"""

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Dict, Optional
import os
import requests
from datetime import datetime
from loguru import logger
from app.business_prompts import get_business_prompt, get_available_business_types, get_business_type_display_name

app = FastAPI(title="Fixed Backend Intelligence", description="Rapports longs cabinet de conseil - version stable")

# Configuration
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
VECTOR_SERVICE_URL = "http://vector-service:8002"

# Mod√®les Pydantic
class BusinessAnalysisRequest(BaseModel):
    business_type: str
    analysis_type: str
    query: str
    title: Optional[str] = None

class AnalysisResponse(BaseModel):
    analysis_type: str
    business_type: str
    title: str
    content: str
    sources: List[Dict]
    metadata: Dict
    timestamp: str

def search_documents_safe(query: str, top_k: int = 10) -> List[Dict]:
    """Recherche vectorielle avec gestion d'erreurs robuste"""
    try:
        response = requests.post(
            f"{VECTOR_SERVICE_URL}/search",
            json={"query": query, "top_k": top_k},
            timeout=10
        )
        
        if response.status_code == 200:
            result = response.json()
            return result.get("results", [])
        else:
            logger.warning(f"Vector search failed: {response.status_code}")
            return []
            
    except requests.exceptions.Timeout:
        logger.error("Vector search timeout")
        return []
    except requests.exceptions.ConnectionError:
        logger.error("Vector search connection error")
        return []
    except Exception as e:
        logger.error(f"Vector search error: {e}")
        return []

def format_context_safe(documents: List[Dict]) -> str:
    """Formate contexte de mani√®re s√©curis√©e"""
    if not documents:
        return "Aucun document de r√©f√©rence disponible."
    
    context = "## DOCUMENTS DE R√âF√âRENCE\n\n"
    for i, doc in enumerate(documents[:6], 1):  # Limiter √† 6 docs
        try:
            doc_text = str(doc.get('text', ''))[:500]  # Limiter texte
            score = float(doc.get('score', 0))
            doc_id = str(doc.get('doc_id', 'N/A'))
            context += f"**[R√©f. {i}]** (Score: {score:.3f}):\n{doc_text}...\n\n"
        except Exception as e:
            logger.warning(f"Error formatting document {i}: {e}")
            continue
    
    return context

def create_optimized_prompt(business_type: str, analysis_type: str, query: str, context: str) -> str:
    """Cr√©e prompts optimis√©s pour √©viter les erreurs"""
    
    # Templates courts et efficaces
    prompt_templates = {
        "finance_banque": f"""ANALYSE BANCAIRE STRAT√âGIQUE

MISSION: {query}

CONTEXTE:
{context[:4000]}  

G√âN√àRE UN RAPPORT PROFESSIONNEL STRUCTUR√â (10+ pages):

# RAPPORT STRAT√âGIQUE BANCAIRE

## üéØ SYNTH√àSE EX√âCUTIVE
- Enjeux transformation sectorielle [R√©f. X]
- Recommandations prioritaires avec ROI
- Timeline et investissements

## üìä ANALYSE SECTORIELLE  
- Taille march√© et croissance [R√©f. X]
- Segmentation clients [R√©f. X]
- Performance secteur [R√©f. X]
- Technologies √©mergentes [R√©f. X]

## ‚öîÔ∏è CONCURRENCE
- Leaders vs challengers [R√©f. X]
- Forces/faiblesses [R√©f. X]
- Strat√©gies diff√©renciation [R√©f. X]

## üí° RECOMMANDATIONS
- Plan action 12-18 mois [R√©f. X]
- Business case ROI [R√©f. X]
- Gestion risques [R√©f. X]

## üìà PROJECTIONS
- Scenarios 2025-2030 [R√©f. X]
- KPIs de suivi [R√©f. X]

Minimum 5000 mots. Cite [R√©f. X] pour toute donn√©e factuelle.""",

        "tech_digital": f"""ANALYSE TRANSFORMATION DIGITALE

MISSION: {query}

CONTEXTE:
{context[:4000]}

G√âN√àRE RAPPORT TECHNIQUE STRAT√âGIQUE (10+ pages):

# RAPPORT TRANSFORMATION DIGITALE

## üéØ VISION EX√âCUTIVE
- Enjeux transformation [R√©f. X]
- ROI digital [R√©f. X]
- Roadmap strat√©gique

## üîß √âTAT DES LIEUX TECH
- Maturit√© technologique [R√©f. X]
- Gaps et opportunit√©s [R√©f. X]
- Benchmark secteur [R√©f. X]

## üöÄ INNOVATION
- Technologies cl√©s [R√©f. X]
- Use cases business [R√©f. X]
- Investissements [R√©f. X]

## üìã PLAN D'ACTION
- Phases transformation [R√©f. X]
- Budget et timeline [R√©f. X]
- Organisation et skills [R√©f. X]

Minimum 5000 mots. R√©f√©rencer [R√©f. X] syst√©matiquement.""",

        "retail_commerce": f"""ANALYSE RETAIL STRAT√âGIQUE

MISSION: {query}

CONTEXTE:
{context[:4000]}

G√âN√àRE RAPPORT RETAIL COMPLET (10+ pages):

# RAPPORT STRAT√âGIE RETAIL

## üéØ SYNTH√àSE RETAIL
- Tendances march√© [R√©f. X]
- Transformation omnicanal [R√©f. X]
- Strat√©gies gagnantes

## üõçÔ∏è MARCH√â ET CLIENTS
- √âvolution consommation [R√©f. X]
- Segments clients [R√©f. X]
- Parcours d'achat [R√©f. X]

## üè™ CONCURRENCE
- Players traditionnels vs pure players [R√©f. X]
- Innovations retail [R√©f. X]
- Diff√©renciation [R√©f. X]

## üí° RECOMMANDATIONS
- Strat√©gie omnicanal [R√©f. X]
- Technologies retail [R√©f. X]
- Plan d√©ploiement [R√©f. X]

Minimum 5000 mots. Citer [R√©f. X] pour donn√©es factuelles."""
    }
    
    return prompt_templates.get(business_type, prompt_templates["finance_banque"])

def call_openai_safe(prompt: str, business_type: str) -> str:
    """Appel OpenAI s√©curis√© avec gestion d'erreurs compl√®te"""
    try:
        if not OPENAI_API_KEY or OPENAI_API_KEY == "":
            return "‚ö†Ô∏è **Configuration OpenAI requise**\n\nVeuillez configurer la variable OPENAI_API_KEY dans votre fichier .env"
        
        # Import OpenAI
        try:
            import openai
        except ImportError:
            return "‚ùå **Module OpenAI manquant**\n\nVeuillez installer: pip install openai"
        
        # System prompts par m√©tier
        system_prompts = {
            "finance_banque": """Tu es un consultant senior McKinsey sp√©cialis√© en strat√©gie bancaire. 
                              G√©n√®re des rapports structur√©s avec analyses quantifi√©es et recommandations actionnables.
                              Utilise exclusivement les donn√©es des documents fournis avec r√©f√©rences [R√©f. X].""",
                              
            "tech_digital": """Tu es un consultant BCG expert en transformation digitale. 
                             G√©n√®re des analyses techniques d√©taill√©es avec business case et ROI.
                             Base tes analyses sur les documents fournis avec r√©f√©rences [R√©f. X].""",
                             
            "retail_commerce": """Tu es un consultant Bain expert en retail et commerce. 
                                G√©n√®re des analyses avec insights consommateurs et recommandations op√©rationnelles.
                                Utilise les documents fournis avec r√©f√©rences [R√©f. X]."""
        }
        
        system_prompt = system_prompts.get(business_type, system_prompts["finance_banque"])
        
        # Client OpenAI
        try:
            client = openai.OpenAI(api_key=OPENAI_API_KEY)
            
            # V√©rifier taille prompt
            if len(prompt) > 15000:
                logger.warning(f"Prompt tr√®s long ({len(prompt)} chars), troncature appliqu√©e")
                prompt = prompt[:15000] + "\n\n[...Prompt tronqu√© pour limites techniques. Continuer l'analyse avec les √©l√©ments disponibles...]"
            
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=8000
            )
            
            return response.choices[0].message.content
            
        except Exception as api_error:
            logger.error(f"OpenAI API error: {api_error}")
            return f"‚ùå **Erreur API OpenAI**\n\n{str(api_error)[:300]}\n\nV√©rifiez votre cl√© API et votre quota."
        
    except Exception as e:
        logger.error(f"Critical error in OpenAI call: {e}")
        return f"‚ùå **Erreur critique**\n\n{str(e)[:300]}"

async def generate_business_analysis_safe(business_type: str, analysis_type: str, query: str, title: str = None) -> AnalysisResponse:
    """G√©n√®re analyse avec gestion d'erreurs compl√®te"""
    try:
        logger.info(f"Starting analysis: {business_type}/{analysis_type}")
        
        # 1. Recherche documents s√©curis√©e
        documents = search_documents_safe(query, top_k=8)
        logger.info(f"Found {len(documents)} documents")
        
        # 2. Formatage contexte s√©curis√©
        context = format_context_safe(documents)
        
        # 3. Cr√©ation prompt optimis√©
        prompt = create_optimized_prompt(business_type, analysis_type, query, context)
        
        # 4. Appel OpenAI s√©curis√©
        content = call_openai_safe(prompt, business_type)
        
        # 5. Construction r√©ponse
        return AnalysisResponse(
            analysis_type=analysis_type,
            business_type=business_type,
            title=title or f"Rapport {get_business_type_display_name(business_type)} - {analysis_type.replace('_', ' ').title()}",
            content=content,
            sources=[{
                "doc_id": d.get("doc_id", "N/A"),
                "score": d.get("score", 0),
                "text": str(d.get("text", ""))[:200]
            } for d in documents],
            metadata={
                "query": query,
                "business_type": business_type,
                "documents_found": len(documents),
                "analysis_length": "extended_report",
                "model": "gpt-4o-mini",
                "max_tokens": 8000,
                "status": "success"
            },
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as e:
        logger.error(f"Error in business analysis: {e}")
        # Retourner une r√©ponse d'erreur plut√¥t qu'une exception
        return AnalysisResponse(
            analysis_type=analysis_type,
            business_type=business_type,
            title=title or "Analyse √©chou√©e",
            content=f"‚ùå **Erreur lors de l'analyse**\n\n{str(e)[:500]}\n\nVeuillez r√©essayer ou contacter le support.",
            sources=[],
            metadata={
                "query": query,
                "business_type": business_type,
                "error": str(e),
                "status": "failed"
            },
            timestamp=datetime.now().isoformat()
        )

# Endpoints
@app.get("/health")
def health():
    """Health check avec diagnostics"""
    return {
        "status": "healthy", 
        "service": "fixed-backend",
        "openai_configured": bool(OPENAI_API_KEY),
        "vector_service": VECTOR_SERVICE_URL,
        "business_types": get_available_business_types()
    }

@app.get("/business-types")
def get_business_types():
    """Types de m√©tier disponibles"""
    try:
        return {
            "business_types": [
                {"key": bt, "display_name": get_business_type_display_name(bt)} 
                for bt in get_available_business_types()
            ]
        }
    except Exception as e:
        logger.error(f"Error getting business types: {e}")
        return {
            "business_types": [
                {"key": "finance_banque", "display_name": "üè¶ Finance & Banque"},
                {"key": "tech_digital", "display_name": "üíª Tech & Digital"},
                {"key": "retail_commerce", "display_name": "üõçÔ∏è Retail & Commerce"}
            ]
        }

@app.post("/extended-analysis", response_model=AnalysisResponse)
async def extended_analysis(request: BusinessAnalysisRequest):
    """G√©n√®re rapports longs style cabinet conseil - Version robuste"""
    return await generate_business_analysis_safe(
        request.business_type,
        request.analysis_type,
        request.query,
        request.title
    )

@app.get("/test-openai")
async def test_openai():
    """Test de connectivit√© OpenAI"""
    try:
        if not OPENAI_API_KEY:
            return {"status": "error", "message": "OPENAI_API_KEY not configured"}
        
        import openai
        client = openai.OpenAI(api_key=OPENAI_API_KEY)
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": "Hello, test simple"}],
            max_tokens=10
        )
        
        return {
            "status": "success", 
            "message": "OpenAI API functional",
            "model": "gpt-4o-mini",
            "response": response.choices[0].message.content
        }
        
    except Exception as e:
        return {"status": "error", "message": str(e)}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8006)
