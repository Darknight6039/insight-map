"""
Backend Service - Version robuste sans points d'√©chec
"""

from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware

from pydantic import BaseModel
from typing import List, Dict, Optional, AsyncGenerator
import os
import requests
import json
import asyncio
from datetime import datetime
from loguru import logger
from importlib import metadata
from app.business_prompts import get_business_prompt, get_available_business_types, get_business_type_display_name, get_trusted_sources, TRUSTED_SOURCES_INSTRUCTION

# Import SDK Perplexity (compatible OpenAI SDK)
try:
    from openai import OpenAI
    OPENAI_SDK_AVAILABLE = True
except ImportError:
    OPENAI_SDK_AVAILABLE = False
    logger.error("SDK OpenAI package not available (required for Perplexity API compatibility)")

app = FastAPI(title="Backend Intelligence Service", description="Rapports longs cabinet de conseil - version robuste")

# Configuration CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000"],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)

# Configuration - Perplexity API
PERPLEXITY_API_KEY = os.getenv("PERPLEXITY_API_KEY", "")
PERPLEXITY_BASE_URL = "https://api.perplexity.ai"
VECTOR_SERVICE_URL = "http://vector-service:8002"
DOCUMENT_SERVICE_URL = "http://document-service:8001"

# Configuration multi-mod√®les Sonar optimis√©e par cas d'usage
# IMPORTANT: Tous les rapports (standards et approfondis) utilisent sonar-pro
PERPLEXITY_MODELS = {
    "chat": os.getenv("PERPLEXITY_MODEL_CHAT", "sonar"),              # Chat court, tests
    "analysis": os.getenv("PERPLEXITY_MODEL_ANALYSIS", "sonar-pro"),  # TOUS les rapports
    "reasoning": os.getenv("PERPLEXITY_MODEL_REASONING", "sonar-reasoning-pro") # R√©serv√© usage futur - Migration depuis sonar-reasoning (d√©pr√©ci√© le 15/12/2025)
}

def get_model_for_task(task_type: str) -> str:
    """S√©lectionne le mod√®le Sonar appropri√© selon la t√¢che"""
    return PERPLEXITY_MODELS.get(task_type, PERPLEXITY_MODELS["chat"])

# Cache pour les m√©tadonn√©es des documents
_document_metadata_cache = {}

# Mod√®les Pydantic
class BusinessAnalysisRequest(BaseModel):
    business_type: Optional[str] = "general"  # Optional, defaults to generic
    analysis_type: str
    query: str
    title: Optional[str] = None

class AnalysisResponse(BaseModel):
    analysis_type: str
    business_type: str
    title: str
    content: str
    sources: List[Dict]
    metadata: Dict
    timestamp: str

class ChatRequest(BaseModel):
    message: str
    business_type: Optional[str] = None
    conversation_history: Optional[List[Dict]] = []

class SchedulerAnalysisRequest(BaseModel):
    """Request model for scheduler-service watch executions"""
    query: str
    analysis_type: str
    sector: Optional[str] = "general"
    deep_analysis: Optional[bool] = False

class ChatResponse(BaseModel):
    response: str
    business_context: str
    sources: List[Dict]
    metadata: Dict
    timestamp: str

def get_document_metadata(doc_id: int) -> Optional[Dict]:
    """R√©cup√®re les m√©tadonn√©es r√©elles d'un document depuis le document-service"""
    # V√©rifier le cache d'abord
    if doc_id in _document_metadata_cache:
        return _document_metadata_cache[doc_id]
    
    try:
        response = requests.get(
            f"{DOCUMENT_SERVICE_URL}/document/{doc_id}",
            timeout=5
        )
        
        if response.status_code == 200:
            metadata = response.json()
            # Mettre en cache
            _document_metadata_cache[doc_id] = metadata
            return metadata
        else:
            logger.warning(f"Failed to get document metadata for doc_id={doc_id}: {response.status_code}")
            return None
            
    except Exception as e:
        logger.error(f"Error fetching document metadata for doc_id={doc_id}: {e}")
        return None

def search_documents_safe(query: str, top_k: int = 10) -> List[Dict]:
    """Recherche vectorielle avec gestion d'erreurs robuste"""
    try:
        response = requests.post(
            f"{VECTOR_SERVICE_URL}/search",
            json={"query": query, "top_k": top_k},
            timeout=10
        )
        
        if response.status_code == 200:
            result = response.json()
            # The vector-service returns a LIST of results. Also support dict forms.
            if isinstance(result, list):
                return result
            if isinstance(result, dict):
                return result.get("results", result.get("data", []))
            return []
        else:
            logger.warning(f"Vector search failed: {response.status_code}")
            return []
            
    except requests.exceptions.Timeout:
        logger.error("Vector search timeout")
        return []
    except requests.exceptions.ConnectionError:
        logger.error("Vector search connection error")
        return []
    except Exception as e:
        logger.error(f"Vector search error: {e}")
        return []

def enrich_source_with_apa(doc: Dict, index: int) -> Dict:
    """Enrichit une source avec m√©tadonn√©es APA pour citations acad√©miques"""
    doc_id = doc.get("doc_id", "N/A")
    text = str(doc.get("text", ""))
    score = doc.get("score", 0)
    segment_index = doc.get("segment_index", 0)
    
    # R√©cup√©rer les vraies m√©tadonn√©es du document
    metadata = None
    if isinstance(doc_id, int):
        metadata = get_document_metadata(doc_id)
    
    # Utiliser les vraies m√©tadonn√©es si disponibles
    if metadata:
        filename = metadata.get("filename", "Document inconnu")
        title = metadata.get("title", filename)
        upload_date = metadata.get("upload_date", "")
        pages_count = metadata.get("pages_count", 0)
        
        # Extraire l'ann√©e de la date d'upload
        try:
            year = datetime.fromisoformat(upload_date.replace('Z', '+00:00')).year if upload_date else 2024
        except:
            year = 2024
        
        # Calculer la page approximative bas√©e sur le segment
        page = min(segment_index + 1, pages_count) if pages_count > 0 else segment_index + 1
        
        # D√©terminer l'auteur et le type bas√©s sur le nom du fichier et le contenu
        if "study" in filename.lower() or "√©tude" in filename.lower():
            author = "D√©partement √âtudes et Recherche"
            doc_type = "√âtude de march√©"
        elif "report" in filename.lower() or "rapport" in filename.lower():
            author = "Direction Strat√©gie"
            doc_type = "Rapport strat√©gique"
        elif "analysis" in filename.lower() or "analyse" in filename.lower():
            author = "√âquipe Analyse"
            doc_type = "Analyse sectorielle"
        else:
            # D√©termine le type bas√© sur le contenu
            if "march√©" in text.lower() or "market" in text.lower():
                author = "Axial Market Intelligence"
                doc_type = "Rapport de march√©"
            elif "tech" in text.lower() or "digital" in text.lower():
                author = "Axial Tech Watch"
                doc_type = "Veille technologique"
            elif "risque" in text.lower() or "risk" in text.lower():
                author = "Axial Risk Assessment"
                doc_type = "Analyse de risques"
            else:
                author = "Axial Intelligence"
                doc_type = "Document d'analyse"
        
        # Format APA: Auteur. (Ann√©e). Titre. Type, p. page.
        apa_citation = f"{author}. ({year}). {title}. {doc_type}, p. {page}."
        
    else:
        # Fallback sur les m√©tadonn√©es g√©n√©riques si pas de metadata disponible
        year = 2024
        author = "Axial Research"
        title = f"Document d'analyse strat√©gique #{doc_id}"
        page = (doc_id % 50) + 1 if isinstance(doc_id, int) else 1
        doc_type = "Document interne"
        apa_citation = f"{author}. ({year}). {title}. {doc_type}, p. {page}."
    
    return {
        "id": index,
        "doc_id": doc_id,
        "title": title,
        "author": author,
        "year": year,
        "page": page,
        "doc_type": doc_type,
        "text": text[:300],  # Preview plus long
        "score": score,
        "apa_citation": apa_citation,
        "document_url": f"/documents/{doc_id}.pdf" if doc_id != "N/A" else None
    }

def format_context_safe(documents: List[Dict]) -> str:
    """Formate contexte de mani√®re s√©curis√©e"""
    if not documents:
        return "Aucun document de r√©f√©rence disponible."
    
    context = "## DOCUMENTS DE R√âF√âRENCE\n\n"
    for i, doc in enumerate(documents[:6], 1):  # Limiter √† 6 docs
        try:
            doc_text = str(doc.get('text', ''))[:500]  # Limiter texte
            score = float(doc.get('score', 0))
            doc_id = str(doc.get('doc_id', 'N/A'))
            context += f"**[R√©f. {i}]** (Score: {score:.3f}):\n{doc_text}...\n\n"
        except Exception as e:
            logger.warning(f"Error formatting document {i}: {e}")
            continue
    
    return context

def create_optimized_prompt(business_type: str, analysis_type: str, query: str, context: str) -> str:
    """Cr√©e prompts concis et efficaces pour rapports de cabinet de conseil avec sonar-pro"""
    
    # D√©tection rapport approfondi (60 sources)
    if "approfondi" in analysis_type.lower():
        prompt_templates_deep = {
            "finance_banque": f"""Tu es un consultant senior McKinsey sp√©cialis√© en strat√©gie bancaire - Rapport Approfondi.

**MISSION** : {query}

**CONTEXTE DOCUMENTAIRE** :
{context[:5000]}

**FORMAT** : Rapport ultra-d√©taill√© (8000-10000 mots) avec 60 sources MINIMUM

## EXIGENCES SOURCES (RAPPORTS APPROFONDIS) :
- Utilise recherche web Perplexity exhaustive
- MINIMUM 60 sources organis√©es par cat√©gorie

## HI√âRARCHIE SOURCES STRICTE (60 sources) - INSTITUTIONS ET CABINETS UNIQUEMENT :
- 42 sources institutionnelles (70%) : INSEE, Banque de France, ACPR, AMF, minist√®res, BCE, EBA, OCDE, FMI
- 18 sources cabinets de conseil (30%) : McKinsey, BCG, Bain, Deloitte, PwC, EY, KPMG
- AUCUNE source m√©dia (Les √âchos, Bloomberg, FT, etc.) - STRICTEMENT INTERDIT

## RECHERCHE EN 2 PHASES :
Phase 1 : 42 sources institutionnelles minimum (70%)
Phase 2 : 18 sources cabinets de conseil maximum (30%)

## STRUCTURE RAPPORT EXHAUSTIF :

1. **Executive Summary** (800-1000 mots)
   - 8-10 KPIs cl√©s avec 3-4 sources crois√©es chacun
   - Top 5 recommandations avec ROI, budget, timeline

2. **Analyse Sectorielle Approfondie** (2500-3000 mots)
   - Dimensionnement march√© d√©taill√© (10+ m√©triques)
   - Segmentation compl√®te avec donn√©es chiffr√©es
   - √âvolutions historiques 5 ans + projections 3 ans
   - MINIMUM 25 donn√©es chiffr√©es avec sources crois√©es

3. **Analyse Concurrentielle Exhaustive** (2000-2500 mots)
   - Tableau comparatif 12+ crit√®res √ó 8-10 acteurs
   - Chaque cellule doit avoir sa source
   - Analyse d√©taill√©e forces/faiblesses par acteur
   - Cartographie positionnement strat√©gique
   - MINIMUM 3 tableaux comparatifs d√©taill√©s

4. **Recommandations Strat√©giques** (2000-2500 mots)
   - 8-10 recommandations ultra-d√©taill√©es
   - Chaque recommandation : budget, ROI, timeline, risques, KPIs
   - Plans d'action op√©rationnels concrets
   - Analyses co√ªts-b√©n√©fices d√©taill√©es

5. **Projections et Sc√©narios** (1500-2000 mots)
   - 3 sc√©narios mod√©lis√©s (optimiste, central, pessimiste)
   - Analyses de sensibilit√© sur 4-5 variables
   - Tableaux financiers d√©taill√©s

6. **R√©f√©rences Bibliographiques** (60 sources MINIMUM)
   - Section Sources Institutionnelles Fran√ßaises (20 sources)
   - Section Sources Institutionnelles Europ√©ennes/Internationales (22 sources)
   - Section Cabinets de Conseil (18 sources)
   - Format APA obligatoire: Auteur. (Ann√©e). Titre. Publication. URL

## IMP√âRATIFS QUALIT√â :
- MINIMUM 60 sources organis√©es par cat√©gorie
- MINIMUM 50 donn√©es chiffr√©es avec sources crois√©es
- MINIMUM 5 tableaux comparatifs d√©taill√©s
- Croisement 3-4 sources pour chaque donn√©e strat√©gique
- Citations denses : chaque paragraphe doit avoir 3-5 citations minimum

G√©n√®re maintenant ce rapport exhaustif :""",

            "tech_digital": f"""Tu es un consultant BCG expert en transformation digitale - Rapport Approfondi.

**MISSION** : {query}

**CONTEXTE** : {context[:5000]}

**FORMAT** : Rapport ultra-d√©taill√© (8000-10000 mots) avec 60 sources MINIMUM

## EXIGENCES SOURCES (RAPPORTS APPROFONDIS) :
- Utilise recherche web Perplexity exhaustive
- MINIMUM 60 sources organis√©es par cat√©gorie

## HI√âRARCHIE SOURCES STRICTE (60 sources) - INSTITUTIONS ET CABINETS UNIQUEMENT :
- 42 sources institutionnelles/analystes (70%) : Gartner, IDC, Forrester, Commission europ√©enne, OCDE
- 18 sources cabinets de conseil (30%) : McKinsey Digital, BCG Digital Ventures, Accenture, Deloitte
- AUCUNE source m√©dia tech (TechCrunch, Wired, ZDNet, etc.) - STRICTEMENT INTERDIT

## IMP√âRATIFS :
- 50+ donn√©es chiffr√©es avec sources crois√©es
- 5+ tableaux comparatifs d√©taill√©s
- Rapport 8000-10000 mots

G√©n√®re maintenant ce rapport exhaustif :""",

            "retail_commerce": f"""Tu es un consultant Bain expert retail - Rapport Approfondi.

**MISSION** : {query}

**CONTEXTE** : {context[:5000]}

**FORMAT** : Rapport ultra-d√©taill√© (8000-10000 mots) avec 60 sources MINIMUM

## EXIGENCES SOURCES (RAPPORTS APPROFONDIS) :
- Utilise recherche web Perplexity exhaustive
- MINIMUM 60 sources organis√©es par cat√©gorie

## HI√âRARCHIE SOURCES STRICTE (60 sources) - INSTITUTIONS ET CABINETS UNIQUEMENT :
- 42 sources institutionnelles (70%) : INSEE, FEVAD, CREDOC, Eurostat, Commission europ√©enne, OCDE
- 18 sources cabinets de conseil (30%) : McKinsey Retail, BCG Consumer, Bain, Deloitte, PwC
- AUCUNE source m√©dia commerce (LSA, e-commerce mag, etc.) - STRICTEMENT INTERDIT

## IMP√âRATIFS :
- 50+ donn√©es chiffr√©es avec sources crois√©es
- 5+ tableaux comparatifs d√©taill√©s
- Rapport 8000-10000 mots

G√©n√®re maintenant ce rapport exhaustif :"""
        }
        
        return prompt_templates_deep.get(business_type, prompt_templates_deep["finance_banque"])
    
    # Templates standards (40-60 sources) - code existant
    prompt_templates = {
        "finance_banque": f"""Tu es un consultant senior McKinsey sp√©cialis√© en strat√©gie bancaire.

**MISSION** : {query}

**CONTEXTE DOCUMENTAIRE** :
{context[:5000]}

**FORMAT ATTENDU** :

G√©n√®re un rapport strat√©gique professionnel ultra-d√©taill√© (6000-8000 mots) avec :

## EXIGENCES SOURCES (TOUS RAPPORTS) - INSTITUTIONS ET CABINETS UNIQUEMENT :
- MINIMUM 40-60 sources institutionnelles et cabinets de conseil
- R√©partition: 70% institutionnelles (INSEE, BCE, OCDE, etc.), 30% cabinets (McKinsey, BCG, etc.)
- AUCUNE source m√©dia, presse, blog - STRICTEMENT INTERDIT
- Utilise recherche web Perplexity exhaustive pour donn√©es actuelles

## Structure Obligatoire avec Num√©rotation Hi√©rarchique

IMPORTANT: Tous les titres doivent √™tre num√©rot√©s hi√©rarchiquement:
- Niveau ## : 1, 2, 3, 4, etc.
- Niveau ### : 1.1, 1.2, 2.1, 2.2, etc.
- Niveau #### : 1.1.1, 1.1.2, 2.1.1, etc.

Exemple:
## 1. Executive Summary
### 1.1 Synth√®se Quantifi√©e
### 1.2 Recommandations Cl√©s

## 2. Analyse Sectorielle Quantifi√©e
### 2.1 Dimensionnement March√©
#### 2.1.1 Taille Actuelle
#### 2.1.2 Projections

## Style R√©dactionnel - Contenu Enrichi

IMPORTANT: Chaque section doit alterner paragraphes narratifs et bullet points:

STRUCTURE REQUISE POUR CHAQUE SECTION:
1. Paragraphe d'introduction (3-5 phrases) qui contextualise le sujet
2. D√©veloppement avec 2-3 paragraphes narratifs d√©taill√©s (4-6 phrases chacun)
3. Points cl√©s synth√©tis√©s en bullet points pour les donn√©es chiffr√©es
4. Paragraphe de transition ou conclusion (2-3 phrases) avant la section suivante

EXIGENCES DE R√âDACTION:
- Minimum 60% de contenu en paragraphes narratifs complets
- Maximum 40% de contenu en bullet points (r√©serv√©s aux listes de donn√©es/chiffres)
- Chaque paragraphe doit d√©velopper une id√©e compl√®te avec exemples et sources
- Style fluide avec transitions naturelles entre paragraphes
- Phrases vari√©es et bien articul√©es (pas de style t√©l√©graphique)
- Connecteurs logiques pour lier les id√©es (ainsi, en effet, par cons√©quent, n√©anmoins, etc.)

EXEMPLE DE STRUCTURE:
### 2.1 Dimensionnement du March√©

Le march√© bancaire fran√ßais repr√©sente aujourd'hui un √©cosyst√®me dynamique en pleine transformation (INSEE, 2024). L'analyse des donn√©es r√©centes r√©v√®le une croissance soutenue port√©e par la digitalisation et l'√©volution des comportements clients (Banque de France, 2024).

L'analyse d√©taill√©e r√©v√®le plusieurs tendances structurantes qui red√©finissent le paysage concurrentiel. Les n√©obanques captent d√©sormais 8% du march√© des particuliers, une progression de +45% en deux ans (ACPR, 2024). Cette dynamique s'accompagne d'une consolidation du secteur traditionnel, o√π les cinq premi√®res banques concentrent 65% des parts de march√© (BCE, 2024).

Ces √©volutions s'accompagnent de transformations profondes des mod√®les √©conomiques. L'investissement technologique repr√©sente d√©sormais 12-15% des budgets, contre 6-8% il y a cinq ans (McKinsey, 2024). Les √©tablissements pionniers observent une am√©lioration de leur ratio co√ªt/revenu de 5-8 points (BCG, 2024).

**Donn√©es cl√©s du march√©:**
- Taille: 450 Md‚Ç¨ de revenus (INSEE, 2024)
- Croissance: +3.2% CAGR 2021-2024 (Banque de France, 2024)
- Parts de march√©: Top 5 = 65% (ACPR, 2024)
- Marge nette moyenne: 28% (BCE, 2024)

En synth√®se, le march√© d√©montre une r√©silience notable face aux disruptions technologiques. Les acteurs qui r√©ussissent combinent solidit√© financi√®re historique et agilit√© num√©rique, avec des investissements tech atteignant 450-600M‚Ç¨ par an pour les leaders (McKinsey, 2024).

1. **Executive Summary** (500-700 mots)
   - Synth√®se quantifi√©e : 5-8 KPIs cl√©s avec sources APA (Auteur, Ann√©e)
   - Top 3 recommandations avec ROI estim√© et timeline pr√©cis

2. **Analyse Sectorielle Quantifi√©e** (1500-2000 mots)
   - Dimensionnement march√© avec croisement de sources :
     * Taille actuelle en M‚Ç¨/M$ [sources multiples]
     * CAGR 3 derni√®res ann√©es [sources crois√©es]
     * Pr√©visions 3 prochaines ann√©es avec hypoth√®ses [sources]
     * Parts de march√© top 5-10 acteurs avec √©volution [sources]
   - Segmentation avec donn√©es pr√©cises pour chaque segment
   - MINIMUM 10-15 donn√©es chiffr√©es avec dates et sources crois√©es

3. **Analyse Concurrentielle Comparative** (1200-1500 mots)
   - Tableau comparatif d√©taill√© : minimum 8 crit√®res √ó 5 concurrents
   - Chaque cellule doit avoir sa source
   - Analyse forces/faiblesses bas√©e sur donn√©es factuelles [sources]
   - √âvolution parts de march√© sur 2-3 ans

4. **Recommandations Strat√©giques Chiffr√©es** (1500-2000 mots)
   - CHAQUE recommandation DOIT inclure :
     * Investissement requis avec fourchette [sources benchmarks]
     * ROI estim√© avec calcul d√©taill√© [sources m√©thodologie]
     * Timeline pr√©cis (semaines/mois)
     * Risques quantifi√©s (probabilit√© % + impact ‚Ç¨)
     * KPIs de suivi (minimum 3 par recommandation)

5. **Projections Financi√®res et Sc√©narios** (1000-1200 mots)
   - 3 sc√©narios OBLIGATOIRES avec mod√©lisation compl√®te :
     * Optimiste : hypoth√®ses + 3-5 drivers cl√©s avec impact %
     * Central : hypoth√®ses baseline avec sources
     * Pessimiste : hypoth√®ses + risques quantifi√©s
   - Tableau de synth√®se comparatif des 3 sc√©narios
   - Analyse de sensibilit√© sur 2-3 variables cl√©s

6. **R√©f√©rences Bibliographiques** (40-60 sources MINIMUM)
   - Sources Institutionnelles (70%) : INSEE, BCE, Banque de France, ACPR, AMF, OCDE, FMI
   - Cabinets de Conseil (30%) : McKinsey, BCG, Bain, Deloitte, PwC, EY, KPMG
   - Format APA obligatoire: Auteur. (Ann√©e). Titre. Publication. URL

## Imp√©ratifs qualit√© STRICTS

‚úÖ QUANTIFICATION SYST√âMATIQUE :
- MINIMUM 20-25 donn√©es chiffr√©es dans le rapport
- Chaque chiffre avec source ET date
- Comparaisons temporelles (√©volution sur 2-3 ans)
- Benchmarks internationaux quand pertinent

‚úÖ CROISEMENT DE SOURCES :
- Donn√©es importantes confirm√©es par 2-3 sources en format APA: (Source1, 2024; Source2, 2024)
- Mention des divergences : "varie entre X (Source1, 2024) et Y (Source2, 2024)"
- Privil√©gier convergence de sources institutionnelles

‚úÖ PR√âCISION TEMPORELLE :
- Toujours date avec citation APA: "En 2024 (INSEE, 2024)", "Sur 2022-2024 (Banque de France, 2024)"
- Distinguer historique, actuel, projections
- P√©rim√®tre avec sources: "En France (INSEE, 2024)", "Europe (BCE, 2024)"

‚úÖ TABLEAUX COMPARATIFS :
- MINIMUM 3 tableaux dans le rapport
- Toutes cellules sourc√©es
- Minimum 3 colonnes √ó 5 lignes

‚úÖ GRAPHIQUES ET VISUALISATIONS :
- Inclure 2-4 graphiques pertinents pour illustrer les donn√©es cl√©s
- Format markdown pour graphiques:
```chart
type: bar|line|pie
title: Titre du graphique
data: {{labels: ["Label1", "Label2", "Label3"], values: [valeur1, valeur2, valeur3]}}
source: (Auteur, Ann√©e)
```
- Types de graphiques appropri√©s:
  * bar: comparaisons entre cat√©gories, parts de march√©
  * line: √©volutions temporelles, tendances
  * pie: r√©partitions, pourcentages
- Chaque graphique doit avoir une source APA

G√©n√®re maintenant ce rapport ultra-document√© et pr√©cis :""",

        "tech_digital": f"""Tu es un consultant BCG expert en transformation digitale.

**MISSION** : {query}

**CONTEXTE** : {context[:5000]}

**FORMAT** : Rapport strat√©gique professionnel (6000-8000 mots) avec :

## EXIGENCES SOURCES - INSTITUTIONS ET CABINETS UNIQUEMENT :
- MINIMUM 40-60 sources institutionnelles et cabinets de conseil
- R√©partition: 70% analystes/institutions (Gartner, IDC, Forrester, Commission EU), 30% cabinets (McKinsey, BCG, Accenture)
- AUCUNE source m√©dia tech (TechCrunch, Wired, ZDNet, etc.) - STRICTEMENT INTERDIT
- Utilise recherche web Perplexity exhaustive pour donn√©es actuelles

## Structure Obligatoire avec Num√©rotation Hi√©rarchique

IMPORTANT: Tous les titres doivent √™tre num√©rot√©s hi√©rarchiquement:
- Niveau ## : 1, 2, 3, 4, etc.
- Niveau ### : 1.1, 1.2, 2.1, 2.2, etc.
- Niveau #### : 1.1.1, 1.1.2, 2.1.1, etc.

Exemple:
## 1. Vision Ex√©cutive
### 1.1 Enjeux Transformation
### 1.2 ROI Estim√©

## 2. √âtat des Lieux Tech
### 2.1 Maturit√© Digitale
#### 2.1.1 Score Global
#### 2.1.2 Analyse D√©taill√©e

## Style R√©dactionnel - Contenu Enrichi

IMPORTANT: Chaque section doit alterner paragraphes narratifs et bullet points:

STRUCTURE REQUISE POUR CHAQUE SECTION:
1. Paragraphe d'introduction (3-5 phrases) qui contextualise le sujet
2. D√©veloppement avec 2-3 paragraphes narratifs d√©taill√©s (4-6 phrases chacun)
3. Points cl√©s synth√©tis√©s en bullet points pour les donn√©es chiffr√©es
4. Paragraphe de transition ou conclusion (2-3 phrases) avant la section suivante

EXIGENCES DE R√âDACTION:
- Minimum 60% de contenu en paragraphes narratifs complets
- Maximum 40% de contenu en bullet points (r√©serv√©s aux listes de donn√©es/chiffres)
- Chaque paragraphe doit d√©velopper une id√©e compl√®te avec exemples et sources
- Style fluide avec transitions naturelles entre paragraphes
- Phrases vari√©es et bien articul√©es (pas de style t√©l√©graphique)
- Connecteurs logiques pour lier les id√©es (ainsi, en effet, par cons√©quent, n√©anmoins, etc.)

EXEMPLE DE STRUCTURE:
### 2.1 Transformation Digitale

La transformation digitale du secteur red√©finit aujourd'hui les standards de comp√©titivit√© (Gartner, 2024). Les entreprises leaders investissent massivement dans l'IA et l'automatisation, avec des budgets moyens en hausse de 35% sur deux ans (IDC, 2024).

L'adoption des technologies cloud computing s'acc√©l√®re de mani√®re exponentielle dans tous les secteurs. Les migrations vers le cloud hybride concernent d√©sormais 68% des grandes entreprises, contre 42% en 2022 (Forrester, 2024). Cette √©volution permet des gains de flexibilit√© et d'efficacit√© op√©rationnelle mesurables, avec une r√©duction des co√ªts IT de 20-30% en moyenne (McKinsey Digital, 2024).

Les investissements dans l'IA g√©n√©rative explosent litt√©ralement depuis 2023. Les d√©penses mondiales atteignent 156 Md$ en 2024, soit une croissance de +78% en un an (IDC, 2024). Les cas d'usage se multiplient : support client automatis√©, g√©n√©ration de code, analyse pr√©dictive, personnalisation marketing (Gartner, 2024).

**Indicateurs cl√©s transformation:**
- Budget IT moyen: 4.5% du CA (+0.8pt vs 2022) (Gartner, 2024)
- Adoption cloud: 68% grandes entreprises (Forrester, 2024)
- ROI moyen IA: 18-25% premi√®re ann√©e (McKinsey, 2024)
- Temps d√©ploiement: -40% avec DevOps (IDC, 2024)

En conclusion, la transformation digitale n'est plus une option mais un imp√©ratif strat√©gique. Les organisations qui excellent combinent vision long terme et capacit√© d'ex√©cution agile, avec des cycles d'innovation r√©duits √† 3-6 mois contre 12-18 mois historiquement (BCG, 2024).

1. **Vision Ex√©cutive** (500-700 mots)
   - Enjeux transformation avec chiffres cl√©s [sources multiples]
   - ROI estim√© avec calcul d√©taill√© [benchmarks sectoriels]
   - Roadmap high-level avec jalons quantifi√©s

2. **√âtat des Lieux Tech Quantifi√©** (1500-2000 mots)
   - Maturit√© digitale : score/10 sur 5-8 dimensions [sources]
   - Gaps identifi√©s avec impact business chiffr√© [donn√©es]
   - Benchmarks sectoriels et internationaux [sources crois√©es]
   - MINIMUM 10 KPIs tech avec comparaisons

3. **Innovation et Technologies** (1200-1500 mots)
   - Technologies cl√©s avec taux d'adoption march√© [sources]
   - Use cases business avec ROI par use case [benchmarks]
   - Investissements requis par technologie [√©tudes]
   - Tableau comparatif technologies (minimum 8 crit√®res √ó 4 techs)

4. **Plan d'Action D√©taill√©** (1500-2000 mots)
   - Phases avec timeline pr√©cis (semaines/mois)
   - Budget d√©taill√© par phase et poste [benchmarks]
   - Organisation : FTE requis par comp√©tence [donn√©es march√©]
   - Risques quantifi√©s avec mitigation [probabilit√©s]
   - MINIMUM 3 tableaux : timeline, budget, ressources

5. **Projections et Business Case** (800-1000 mots)
   - 3 sc√©narios ROI (optimiste/central/pessimiste)
   - KPIs de suivi avec targets chiffr√©s
   - Analyse de sensibilit√©

6. **R√©f√©rences Bibliographiques** (40-60 sources MINIMUM)
   - Sources Analystes/Institutions (70%) : Gartner, IDC, Forrester, Commission europ√©enne, OCDE
   - Cabinets de Conseil (30%) : McKinsey, BCG, Accenture, Deloitte, PwC
   - Format APA obligatoire: Auteur. (Ann√©e). Titre. Publication. URL

EXIGENCES: MINIMUM 25 donn√©es chiffr√©es, 3+ tableaux, croisement sources format APA (Auteur, Ann√©e)

G√©n√®re maintenant ce rapport :""",

        "retail_commerce": f"""Tu es un consultant Bain expert en retail et commerce.

**MISSION** : {query}

**CONTEXTE** : {context[:5000]}

**FORMAT** : Rapport strat√©gique professionnel (6000-8000 mots) avec :

## EXIGENCES SOURCES - INSTITUTIONS ET CABINETS UNIQUEMENT :
- MINIMUM 40-60 sources institutionnelles et cabinets de conseil
- R√©partition: 70% institutionnelles (INSEE, FEVAD, CREDOC, Eurostat), 30% cabinets (McKinsey, BCG, Bain)
- AUCUNE source m√©dia commerce (LSA, e-commerce mag, etc.) - STRICTEMENT INTERDIT
- Utilise recherche web Perplexity exhaustive pour donn√©es actuelles

## Structure Obligatoire avec Num√©rotation Hi√©rarchique

IMPORTANT: Tous les titres doivent √™tre num√©rot√©s hi√©rarchiquement:
- Niveau ## : 1, 2, 3, 4, etc.
- Niveau ### : 1.1, 1.2, 2.1, 2.2, etc.
- Niveau #### : 1.1.1, 1.1.2, 2.1.1, etc.

Exemple:
## 1. Synth√®se Retail Quantifi√©e
### 1.1 Tendances March√©
### 1.2 Strat√©gies Gagnantes

## 2. March√© et Consommateurs
### 2.1 √âvolution Consommation
#### 2.1.1 Chiffres Cl√©s
#### 2.1.2 Segments Clients

## Style R√©dactionnel - Contenu Enrichi

IMPORTANT: Chaque section doit alterner paragraphes narratifs et bullet points:

STRUCTURE REQUISE POUR CHAQUE SECTION:
1. Paragraphe d'introduction (3-5 phrases) qui contextualise le sujet
2. D√©veloppement avec 2-3 paragraphes narratifs d√©taill√©s (4-6 phrases chacun)
3. Points cl√©s synth√©tis√©s en bullet points pour les donn√©es chiffr√©es
4. Paragraphe de transition ou conclusion (2-3 phrases) avant la section suivante

EXIGENCES DE R√âDACTION:
- Minimum 60% de contenu en paragraphes narratifs complets
- Maximum 40% de contenu en bullet points (r√©serv√©s aux listes de donn√©es/chiffres)
- Chaque paragraphe doit d√©velopper une id√©e compl√®te avec exemples et sources
- Style fluide avec transitions naturelles entre paragraphes
- Phrases vari√©es et bien articul√©es (pas de style t√©l√©graphique)
- Connecteurs logiques pour lier les id√©es (ainsi, en effet, par cons√©quent, n√©anmoins, etc.)

EXEMPLE DE STRUCTURE:
### 2.1 √âvolution Comportements Consommateurs

Le paysage de la consommation fran√ßaise conna√Æt une mutation profonde acc√©l√©r√©e par le digital (FEVAD, 2024). Les comportements d'achat se fragmentent entre canaux physiques et digitaux, cr√©ant de nouveaux parcours clients hybrides qui d√©fient les mod√®les traditionnels (INSEE, 2024).

L'e-commerce poursuit sa croissance soutenue avec un taux de p√©n√©tration atteignant 15.2% du commerce de d√©tail total en 2024, contre 13.4% en 2023 (FEVAD, 2024). Cette progression s'accompagne d'une sophistication des attentes : livraison express, personnalisation de l'offre, exp√©rience omnicanale fluide (McKinsey, 2024). Les retailers qui excellent sur ces dimensions capturent 25-30% de parts de march√© suppl√©mentaires (BCG, 2024).

La dynamique retail s'oriente vers des mod√®les phygitaux int√©grant le meilleur des deux mondes. Les magasins physiques √©voluent en showrooms exp√©rientiels avec click & collect, essayage virtuel, et conseillers augment√©s par l'IA (Bain, 2024). Les investissements dans ces technologies atteignent 8-12% des budgets marketing des leaders, g√©n√©rant une hausse de trafic de 15-20% (Deloitte, 2024).

**Indicateurs cl√©s e-commerce:**
- CA e-commerce France: 156 Md‚Ç¨ (+11% vs 2023) (FEVAD, 2024)
- Taux p√©n√©tration: 15.2% du retail total (INSEE, 2024)
- Panier moyen: 68‚Ç¨ (+3‚Ç¨ vs 2023) (CREDOC, 2024)
- Livraison J+1: 78% des sites top 100 (McKinsey, 2024)

En synth√®se, le retail fran√ßais bascule vers des mod√®les hybrides o√π l'excellence op√©rationnelle digitale devient aussi critique que la pr√©sence physique. Les enseignes gagnantes investissent 150-250M‚Ç¨ dans leur transformation omnicanale (BCG, 2024).

1. **Synth√®se Retail Quantifi√©e** (500-700 mots)
   - Tendances march√© avec chiffres cl√©s [sources crois√©es]
   - Strat√©gies gagnantes avec ROI moyen [benchmarks]
   - Top 3 opportunit√©s quantifi√©es

2. **March√© et Consommateurs** (1500-2000 mots)
   - √âvolution consommation : chiffres sur 3 ans [INSEE, panels]
   - Segments clients avec tailles et potentiel [sources]
   - Parcours d'achat avec taux de conversion par canal [√©tudes]
   - Panier moyen et fr√©quence par segment [donn√©es]
   - MINIMUM 12 KPIs clients/march√© avec sources

3. **Analyse Concurrentielle Retail** (1200-1500 mots)
   - Tableau comparatif : 8 crit√®res √ó 5-8 acteurs
   - Players traditionnels vs pure players (CA, croissance, marges)
   - Innovations retail avec impact business [cas d'usage]
   - Parts de march√© online vs offline [sources]

4. **Recommandations Omnicanal** (1500-2000 mots)
   - Strat√©gie omnicanal avec investissements par canal
   - Technologies retail (co√ªts, ROI, timeline)
   - Plan de d√©ploiement phas√© avec KPIs
   - Quick wins vs projets structurants
   - MINIMUM 3 tableaux : investissements, ROI, roadmap

5. **Business Case et Projections** (800-1000 mots)
   - 3 sc√©narios (p√©n√©tration march√©, CA, rentabilit√©)
   - Analyse de sensibilit√© prix/volume
   - KPIs de suivi omnicanal

6. **R√©f√©rences Bibliographiques** (40-60 sources MINIMUM)
   - Sources Institutionnelles (70%) : INSEE, FEVAD, CREDOC, Eurostat, Commission europ√©enne
   - Cabinets de Conseil (30%) : McKinsey, BCG, Bain, Deloitte, PwC
   - Format APA obligatoire: Auteur. (Ann√©e). Titre. Publication. URL

EXIGENCES: MINIMUM 25 donn√©es chiffr√©es, 3+ tableaux, sources format APA (Auteur, Ann√©e)

G√©n√®re maintenant ce rapport :"""
    }
    
    return prompt_templates.get(business_type, prompt_templates["finance_banque"])

def call_perplexity_safe(
    prompt: str, 
    business_type: str, 
    rag_context: str = "",
    task_type: str = "chat"  # NOUVEAU PARAM√àTRE
) -> str:
    """Appel Perplexity s√©curis√© avec RAG interne et recherche web"""
    try:
        if not PERPLEXITY_API_KEY or PERPLEXITY_API_KEY == "":
            return "‚ö†Ô∏è **Configuration Perplexity requise**\n\nVeuillez configurer la variable PERPLEXITY_API_KEY dans votre fichier .env"
        
        # V√©rifier SDK OpenAI (compatible Perplexity)
        if not OPENAI_SDK_AVAILABLE:
            return "‚ùå **SDK OpenAI manquant**\n\nCe SDK est requis pour la compatibilit√© avec Perplexity API.\nVeuillez installer: pip install openai"
        
        # S√©lection dynamique du mod√®le selon la t√¢che
        selected_model = get_model_for_task(task_type)
        
        # Ajuster max_tokens selon le mod√®le
        # sonar-pro (12000 tokens) est utilis√© pour TOUS les rapports (40-60 sources)
        max_tokens_config = {
            "sonar": 8000,        # +2000 pour chat enrichi avec paragraphes
            "sonar-pro": 16000,   # +4000 pour rapports d√©taill√©s avec contenu narratif
            "sonar-reasoning-pro": 20000  # +4000 pour analyses profondes (migration depuis sonar-reasoning)
        }
        max_tokens = max_tokens_config.get(selected_model, 6000)
        
        logger.info(f"Using model: {selected_model} for task: {task_type} (max_tokens: {max_tokens})")
        
        # System prompt g√©n√©rique avec sources institutionnelles et cabinets conseil uniquement
        system_prompt = f"""Tu es un consultant senior sp√©cialis√© en strat√©gie d'entreprise.

{TRUSTED_SOURCES_INSTRUCTION}

R√àGLES OBLIGATOIRES:

1. TITRE PROFESSIONNEL:
   - Commence TOUJOURS par un titre professionnel de 5-10 mots sur la PREMI√àRE LIGNE
   - Format: # Titre du Rapport
   - Le titre doit r√©sumer le sujet analys√© (pas la question pos√©e)

2. CITATIONS APA STRICTES:
   - CHAQUE fait/chiffre DOIT √™tre suivi d'une citation: (Auteur, Ann√©e)
   - Exemple: "Le march√© cro√Æt de 15% (INSEE, 2024)"
   - Pour donn√©es importantes: citer 2-3 sources: (INSEE, 2024; BCE, 2024)
   - JAMAIS de chiffre sans source

3. SECTION SOURCES OBLIGATOIRE EN FIN DE RAPPORT:
   TERMINE TOUJOURS par cette section exacte:

   ## üìö R√©f√©rences Bibliographiques
   
   ### Sources Institutionnelles
   1. INSEE. (2024). Titre du rapport. Rapport officiel. https://insee.fr/...
   2. Banque de France. (2024). Titre. Publication. https://banque-france.fr/...
   3. BCE. (2024). Titre. Rapport. https://ecb.europa.eu/...
   
   ### Cabinets de Conseil
   4. McKinsey & Company. (2024). Titre √©tude. Rapport. https://mckinsey.com/...
   5. BCG. (2024). Titre. √âtude. https://bcg.com/...
   [Continue avec TOUTES les sources utilis√©es - minimum 20 sources]

4. SOURCES AUTORIS√âES EXCLUSIVEMENT:
   - 70% institutionnelles (INSEE, BCE, Banque de France, ACPR, AMF, OCDE, FMI, minist√®res)
   - 30% cabinets de conseil (McKinsey, BCG, Bain, Deloitte, PwC, EY, KPMG, Gartner, IDC)
   - EXCLURE: m√©dias, presse, blogs, forums, entreprises priv√©es

5. STYLE: Professionnel, g√©n√©rique, sans mention de secteur sp√©cifique."""
        
        # Prompt enrichi avec instructions explicites de citation web
        enhanced_prompt = f"""{prompt}

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

INSTRUCTIONS DE RECHERCHE - SOURCES INSTITUTIONNELLES ET CABINETS DE CONSEIL UNIQUEMENT :

üìå PHASE 1 - RECHERCHE STRUCTUR√âE (sources autoris√©es exclusivement) :

PHASE 1A - Sources Institutionnelles (70% minimum) :
- France : INSEE, Banque de France, ACPR, AMF, DARES, DGE, France Strat√©gie, Cour des Comptes
- Europe : BCE, EBA, ESMA, Commission europ√©enne, Eurostat, Parlement europ√©en
- International : OCDE, FMI, BRI (Banque des R√®glements Internationaux), Banque Mondiale
- Organismes publics sp√©cialis√©s (.gov, .gouv.fr, .europa.eu)

PHASE 1B - Cabinets de Conseil (30% maximum) :
- Strat√©gie : McKinsey & Company, Boston Consulting Group (BCG), Bain & Company
- Audit/Conseil : Deloitte, PwC, EY (Ernst & Young), KPMG
- Sp√©cialis√©s : Accenture, Oliver Wyman, Roland Berger, AT Kearney, L.E.K. Consulting
- Tech/Digital : Gartner, IDC, Forrester (uniquement pour analyses technologiques)

‚õî SOURCES STRICTEMENT EXCLUES :
- M√©dias et presse (Les √âchos, Bloomberg, Financial Times, Reuters, etc.)
- Blogs, forums et r√©seaux sociaux
- Entreprises priv√©es (hors cabinets de conseil list√©s)
- Sites d'actualit√© et magazines
- Think tanks non gouvernementaux
- Contenus promotionnels ou commerciaux

HI√âRARCHIE FINALE √Ä RESPECTER :
‚úì 70% sources institutionnelles (priorit√© absolue)
‚úì 30% cabinets de conseil uniquement

Pour TOUS les rapports (40-60 sources) : 
- Minimum 28-42 sources institutionnelles (70%)
- Maximum 12-18 sources cabinets de conseil (30%)
- AUCUNE source m√©dia, presse ou blog

üìå PHASE 2 - CROISEMENT ET VALIDATION DES SOURCES :
- COMPARER syst√©matiquement les chiffres entre sources avec citations APA :
  * Si convergence : "Le march√© atteint 50M‚Ç¨ selon l'INSEE (INSEE, 2024) et la Banque de France (Banque de France, 2024)"
  * Si divergence : "Le march√© varie entre 45M‚Ç¨ (INSEE, 2024) et 52M‚Ç¨ (Banque de France, 2024), moyenne estim√©e √† 48M‚Ç¨"
- Identifier les sources les plus fiables (institutionnelles > m√©dia > blogs)
- Signaler toute contradiction importante entre sources
- Pr√©f√©rer moyenne de plusieurs sources plut√¥t qu'une seule donn√©e

üìå PHASE 3 - R√âDACTION AVEC CITATIONS APA DENSES :
- CHAQUE phrase contenant un fait/chiffre DOIT avoir 1-2 citations APA
- Utiliser citations multiples pour donn√©es importantes : (Source1, 2024; Source2, 2024)
- Ne JAMAIS affirmer sans source : "X% des entreprises..." ‚Üí "X% des entreprises (Auteur, 2024)"
- Varier les sources : √©viter de tout citer depuis 1-2 sources uniquement

üìå PHASE 4 - ANALYSE CRITIQUE DES DONN√âES :
- Mentionner les limitations des donn√©es quand pertinent
- Indiquer la date et le p√©rim√®tre des √©tudes cit√©es avec citation APA
- Exemple: "Selon l'√©tude INSEE 2024 portant sur 1500 entreprises (INSEE, 2024)..."
- Signaler si les donn√©es sont partielles, estim√©es ou d√©finitives

üìå PHASE 5 - BIBLIOGRAPHIE APA COMPL√àTE ET ORGANIS√âE :
Section "## üìö R√©f√©rences Bibliographiques" structur√©e par cat√©gorie :

### Sources Institutionnelles Fran√ßaises
INSEE. (2024). Panorama √©conomique fran√ßais Q3 2024. Rapport trimestriel. https://...
Banque de France. (2024). Situation √©conomique France. Bulletin mensuel. https://...
ACPR. (2024). Rapport annuel supervision bancaire. Publication officielle. https://...

### Sources Institutionnelles Europ√©ennes et Internationales
BCE. (2024). Rapport stabilit√© financi√®re. Publication officielle. https://...
OCDE. (2024). Perspectives √©conomiques. Rapport annuel. https://...
FMI. (2024). World Economic Outlook. Publication. https://...

### Cabinets de Conseil - √âtudes et Rapports
McKinsey & Company. (2024). Transformation sectorielle en France. Rapport. https://...
BCG. (2024). Analyse strat√©gique du march√©. √âtude. https://...
Deloitte. (2024). Tendances et perspectives. Rapport annuel. https://...

MINIMUM REQUIS (TOUS RAPPORTS):
- 40-60 sources institutionnelles et cabinets de conseil uniquement
- R√©partition stricte: 70% institutionnelles, 30% cabinets de conseil
- 28-42 sources institutionnelles + 12-18 sources cabinets conseil
- AUCUNE source m√©dia, presse, blog ou entreprise priv√©e

üìå STRUCTURE ET NUM√âROTATION:
- TOUS les titres doivent √™tre num√©rot√©s hi√©rarchiquement
- Format: ## 1. Titre principal, ### 1.1 Sous-titre, #### 1.1.1 Sous-sous-titre
- Num√©rotation coh√©rente et continue dans tout le rapport
- Facilite la navigation et les r√©f√©rences crois√©es

üìå STYLE R√âDACTIONNEL:
- Style naturel et professionnel comme les exemples de templates
- Phrases claires et bien structur√©es (d√©tailler autant que n√©cessaire pour √™tre complet)
- D√©velopper les √©l√©ments importants en profondeur sans contrainte de longueur
- Transitions naturelles entre paragraphes avec connecteurs logiques
- Vocabulaire pr√©cis mais accessible, √©viter le jargon excessif
- Structure logique et progressive, voix active privil√©gi√©e
- Style professionnel mais fluide et agr√©able √† lire, pas robotique

üìå CONTENU ENRICHI - PARAGRAPHES NARRATIFS OBLIGATOIRES:

POUR CHAQUE SECTION/SOUS-SECTION:
1. Paragraphe d'ouverture contextuel (3-5 phrases compl√®tes)
2. Corps du texte en paragraphes narratifs (minimum 2-3 paragraphes de 4-6 phrases)
3. Bullet points uniquement pour synth√©tiser donn√©es chiffr√©es ou lister des √©l√©ments
4. Paragraphe de transition vers section suivante (2-3 phrases)

RATIO IMP√âRATIF:
- 60-70% paragraphes narratifs avec phrases compl√®tes
- 30-40% bullet points pour donn√©es/listes
- √âviter les sections compos√©es uniquement de bullet points
- Chaque id√©e importante m√©rite un paragraphe de d√©veloppement

QUALIT√â DU CONTENU:
- D√©velopper les analyses en profondeur
- Expliquer les liens de causalit√©
- Fournir des exemples concrets
- Contextualiser chaque donn√©e chiffr√©e
- Privil√©gier le fond sur la forme

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

R√©ponds maintenant avec recherche approfondie et croisement syst√©matique des sources."""
        
        # Client Perplexity utilisant le SDK OpenAI pour compatibilit√©
        try:
            client = OpenAI(
                api_key=PERPLEXITY_API_KEY,
                base_url=PERPLEXITY_BASE_URL,
                timeout=600.0  # 10 minutes pour rapports longs avec paragraphes narratifs
            )
            
            # V√©rifier taille prompt
            if len(enhanced_prompt) > 15000:
                logger.warning(f"Prompt tr√®s long ({len(enhanced_prompt)} chars), troncature appliqu√©e")
                enhanced_prompt = enhanced_prompt[:15000] + "\n\n[...Prompt tronqu√© pour limites techniques. Continuer l'analyse avec les √©l√©ments disponibles...]"
            
            response = client.chat.completions.create(
                model=selected_model,  # ‚Üê Mod√®le dynamique
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": enhanced_prompt}
                ],
                temperature=0.2,  # L√©g√®rement plus cr√©atif pour paragraphes narratifs fluides
                max_tokens=max_tokens  # ‚Üê Dynamique selon mod√®le
            )
            
            return response.choices[0].message.content
            
        except Exception as api_error:
            logger.error(f"Perplexity API error with {selected_model}: {api_error}")
            return f"‚ùå **Erreur API Perplexity ({selected_model})**\n\n{str(api_error)[:300]}\n\nV√©rifiez votre cl√© API et votre quota."
        
    except Exception as e:
        logger.error(f"Critical error in Perplexity call: {e}")
        return f"‚ùå **Erreur critique**\n\n{str(e)[:300]}"

async def generate_business_analysis_safe(business_type: str, analysis_type: str, query: str, title: str = None) -> AnalysisResponse:
    """G√©n√®re analyse avec gestion d'erreurs compl√®te"""
    try:
        is_deep_analysis = "approfondi" in analysis_type.lower()
        logger.info(f"Starting analysis: {business_type}/{analysis_type} (Deep: {is_deep_analysis})")
        
        # 1. Recherche documents s√©curis√©e (augment√© √† 12 pour plus de contexte)
        logger.info("üìä [1/5] Recherche documents RAG...")
        documents = search_documents_safe(query, top_k=12)
        logger.info(f"‚úì [1/5] Trouv√© {len(documents)} documents RAG")
        
        # 2. Formatage contexte s√©curis√©
        logger.info("üìù [2/5] Formatage contexte documentaire...")
        context = format_context_safe(documents)
        logger.info(f"‚úì [2/5] Contexte format√© ({len(context)} caract√®res)")
        
        # 3. Cr√©ation prompt optimis√©
        logger.info("üéØ [3/5] Cr√©ation prompt optimis√©...")
        prompt = create_optimized_prompt(business_type, analysis_type, query, context)
        expected_sources = "60 sources" if is_deep_analysis else "40-60 sources"
        logger.info(f"‚úì [3/5] Prompt cr√©√© (type: {expected_sources})")
        
        # 4. Appel Perplexity s√©curis√© avec RAG
        estimated_time = "90-120s" if is_deep_analysis else "45-60s"
        logger.info(f"üåê [4/5] Appel Perplexity API ({expected_sources}, estimation: {estimated_time})...")
        content = call_perplexity_safe(
            prompt, 
            business_type, 
            rag_context=context,
            task_type="analysis"  # Force sonar-pro pour rapports longs
        )
        logger.info("‚úì [4/5] Contenu g√©n√©r√© par Perplexity")
        
        # 5. Construction r√©ponse avec sources enrichies APA
        logger.info("‚úÖ [5/5] Finalisation du rapport...")
        enriched_sources = [enrich_source_with_apa(d, i+1) for i, d in enumerate(documents)]
        logger.info(f"‚úì [5/5] Rapport finalis√© avec {len(enriched_sources)} sources RAG")
        
        return AnalysisResponse(
            analysis_type=analysis_type,
            business_type=business_type,
            title=title or f"Rapport {get_business_type_display_name(business_type)} - {analysis_type.replace('_', ' ').title()}",
            content=content,
            sources=enriched_sources,
            metadata={
                "query": query,
                "business_type": business_type,
                "documents_found": len(documents),
                "analysis_length": "extended_report",
                "model": get_model_for_task("analysis"),
                "provider": "Perplexity AI",
                "max_tokens": 8000,
                "status": "success",
                "citation_format": "APA"
            },
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as e:
        logger.error(f"Error in business analysis: {e}")
        # Retourner une r√©ponse d'erreur plut√¥t qu'une exception
        return AnalysisResponse(
            analysis_type=analysis_type,
            business_type=business_type,
            title=title or "Analyse √©chou√©e",
            content=f"‚ùå **Erreur lors de l'analyse**\n\n{str(e)[:500]}\n\nVeuillez r√©essayer ou contacter le support.",
            sources=[],
            metadata={
                "query": query,
                "business_type": business_type,
                "error": str(e),
                "status": "failed"
            },
            timestamp=datetime.now().isoformat()
        )

async def generate_chat_response_safe(message: str, business_type: str = None, history: List[Dict] = None) -> ChatResponse:
    """Chat avec Perplexity uniquement (pas de RAG interne)"""
    try:
        # 1. Pas de recherche documents - Perplexity uniquement
        business_context = "Expert IA"  # Toujours g√©n√©rique
        
        # 2. Prompt chat COURT et CONCIS
        chat_prompt = f"""Tu es un assistant expert en intelligence strat√©gique.

QUESTION: {message}

R√àGLES DE R√âPONSE COURTE:
- R√©ponds en 2-4 paragraphes MAXIMUM
- Sois DIRECT et CONCIS
- Cite 1-2 sources pour les faits importants: (Source, Ann√©e)
- PAS de sections, PAS de listes √† puces longues
- Style conversationnel et professionnel
- Va droit au but

R√©ponds maintenant de fa√ßon concise:"""

        # 3. Appel Perplexity direct (pas de RAG interne)
        response_content = call_perplexity_safe(
            chat_prompt, 
            business_type or "finance_banque", 
            rag_context="",
            task_type="chat"  # Force sonar pour chat court
        )
        
        return ChatResponse(
            response=response_content,
            business_context=business_context,
            sources=[],  # Pas de sources RAG internes
            metadata={
                "message": message,
                "business_type": business_type,
                "documents_found": 0,  # RAG d√©sactiv√©
                "model": get_model_for_task("chat"),
                "provider": "Perplexity AI",
                "mode": "perplexity_web_only"
            },
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as e:
        logger.error(f"Error in chat response: {e}")
        return ChatResponse(
            response=f"‚ùå Erreur dans la r√©ponse: {str(e)[:200]}",
            business_context=business_type or "Error",
            sources=[],
            metadata={"error": str(e)},
            timestamp=datetime.now().isoformat()
        )

# Endpoints
@app.get("/health")
def health():
    """Health check avec diagnostics √©tendus"""
    return {
        "status": "healthy", 
        "service": "backend-intelligence-perplexity",
        "perplexity_configured": bool(PERPLEXITY_API_KEY),
        "perplexity_models": PERPLEXITY_MODELS,  # Multi-mod√®les
        "mode": "perplexity_web_only",
        "rag_internal": "disabled",
        "business_types": get_available_business_types(),
        "version": "3.1-multi-model"
    }

@app.get("/business-types")
def get_business_types():
    """Types de m√©tier disponibles"""
    try:
        return {
            "business_types": [
                {"key": bt, "display_name": get_business_type_display_name(bt)} 
                for bt in get_available_business_types()
            ]
        }
    except Exception as e:
        logger.error(f"Error getting business types: {e}")
        return {
            "business_types": [
                {"key": "finance_banque", "display_name": "üè¶ Finance & Banque"},
                {"key": "tech_digital", "display_name": "üíª Tech & Digital"},
                {"key": "retail_commerce", "display_name": "üõçÔ∏è Retail & Commerce"}
            ]
        }

@app.post("/extended-analysis", response_model=AnalysisResponse)
async def extended_analysis(request: BusinessAnalysisRequest):
    """G√©n√®re rapports longs style cabinet conseil - Version robuste"""
    return await generate_business_analysis_safe(
        request.business_type,
        request.analysis_type,
        request.query,
        request.title
    )

@app.post("/business-analysis", response_model=AnalysisResponse)
async def business_analysis(request: BusinessAnalysisRequest):
    """Alias pour compatibilit√©"""
    return await generate_business_analysis_safe(
        request.business_type,
        request.analysis_type,
        request.query,
        request.title
    )

@app.post("/analyze", response_model=AnalysisResponse)
async def analyze(request: SchedulerAnalysisRequest):
    """
    Endpoint pour le scheduler-service - Compatible avec le format des veilles automatiques
    Accepte: query, analysis_type, sector, deep_analysis
    """
    try:
        # Mapper sector vers business_type si n√©cessaire
        business_type = request.sector if request.sector else "general"
        
        # Si deep_analysis est True, s'assurer que analysis_type contient "approfondi"
        analysis_type = request.analysis_type
        if request.deep_analysis and "approfondi" not in analysis_type.lower():
            analysis_type = f"{analysis_type}_approfondie"
        
        # G√©n√©rer le titre automatiquement
        title = f"Veille Automatis√©e - {analysis_type.replace('_', ' ').title()}"
        
        logger.info(f"Scheduler analysis request: {business_type}/{analysis_type} (deep: {request.deep_analysis})")
        
        return await generate_business_analysis_safe(
            business_type=business_type,
            analysis_type=analysis_type,
            query=request.query,
            title=title
        )
    except Exception as e:
        logger.error(f"Error in /analyze endpoint: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/extended-analysis/stream")
async def extended_analysis_stream(request: BusinessAnalysisRequest):
    """G√©n√®re rapports avec streaming SSE et barre de progression en temps r√©el"""
    
    async def generate_sse() -> AsyncGenerator[str, None]:
        try:
            is_deep_analysis = "approfondi" in (request.analysis_type or "").lower()
            
            # Fonction helper pour cr√©er les messages SSE
            def sse_msg(progress: int, step: str, message: str, **kwargs) -> str:
                data = {'progress': progress, 'step': step, 'message': message, **kwargs}
                return f"data: {json.dumps(data)}\n\n"
            
            # √âtape 1: D√©marrage (5%)
            yield sse_msg(5, 'start', 'Demarrage de analyse...')
            await asyncio.sleep(0.5)
            
            # √âtape 2: Recherche documents (15%)
            yield sse_msg(15, 'search', 'Recherche de sources fiables...')
            documents = search_documents_safe(request.query, top_k=12)
            await asyncio.sleep(0.3)
            
            # √âtape 3: Formatage contexte (25%)
            yield sse_msg(25, 'context', 'Preparation du contexte...')
            context = format_context_safe(documents)
            await asyncio.sleep(0.3)
            
            # √âtape 4: Cr√©ation prompt (30%)
            yield sse_msg(30, 'prompt', 'Construction de la requete...')
            prompt = create_optimized_prompt(
                request.business_type or "general",
                request.analysis_type,
                request.query,
                context
            )
            await asyncio.sleep(0.3)
            
            # √âtape 5: Appel Perplexity (35-85%)
            estimated_time = "90-120s" if is_deep_analysis else "45-60s"
            gen_msg = f"Generation du rapport ({estimated_time})..."
            yield sse_msg(35, 'generate', gen_msg)
            
            # Simuler progression pendant g√©n√©ration
            progress_task = asyncio.create_task(simulate_progress_updates())
            
            # Appel r√©el √† Perplexity
            content = call_perplexity_safe(
                prompt,
                request.business_type or "general",
                rag_context=context,
                task_type="analysis"
            )
            
            progress_task.cancel()
            
            # √âtape 6: Extraction du titre (90%)
            yield sse_msg(90, 'title', 'Extraction du titre...')
            
            # Extraire le titre de la premi√®re ligne
            lines = content.strip().split('\n')
            analysis_type_title = request.analysis_type.replace('_', ' ').title() if request.analysis_type else "Analyse"
            generated_title = request.title or analysis_type_title
            for line in lines[:5]:
                if line.startswith('# '):
                    generated_title = line.replace('# ', '').strip()
                    break
            
            await asyncio.sleep(0.3)
            
            # √âtape 7: Finalisation (95%)
            yield sse_msg(95, 'finalize', 'Finalisation du rapport...')
            
            # Enrichir les sources
            enriched_sources = [enrich_source_with_apa(d, i+1) for i, d in enumerate(documents)]
            
            # √âtape 8: Termin√© (100%)
            result = {
                'progress': 100,
                'step': 'done',
                'message': 'Rapport genere avec succes!',
                'done': True,
                'data': {
                    'analysis_type': request.analysis_type,
                    'business_type': request.business_type or 'general',
                    'title': generated_title,
                    'content': content,
                    'sources': enriched_sources,
                    'metadata': {
                        'query': request.query,
                        'documents_found': len(documents),
                        'model': get_model_for_task("analysis"),
                        'provider': 'Perplexity AI'
                    },
                    'timestamp': datetime.now().isoformat()
                }
            }
            yield f"data: {json.dumps(result)}\n\n"
            
        except Exception as e:
            logger.error(f"SSE Analysis error: {e}")
            err_msg = f"Erreur: {str(e)[:200]}"
            yield sse_msg(0, 'error', err_msg, error=True)
    
    return StreamingResponse(
        generate_sse(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )

async def simulate_progress_updates():
    """Simuler des mises √† jour de progression pendant la g√©n√©ration"""
    try:
        for i in range(40, 85, 5):
            await asyncio.sleep(3)  # Toutes les 3 secondes
    except asyncio.CancelledError:
        pass

@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest):
    """Chat intelligent - r√©ponses courtes et concises"""
    return await generate_chat_response_safe(
        request.message,
        request.business_type,
        request.conversation_history
    )

@app.post("/chat/stream")
async def chat_stream_endpoint(request: ChatRequest):
    """Streaming de la r√©ponse du chat - r√©ponses COURTES et CONCISES."""
    async def token_generator():
        try:
            # Prompt pour r√©ponses COURTES (2-4 paragraphes)
            chat_prompt = f"""QUESTION: {request.message}

R√àGLES:
- R√©ponds en 2-4 paragraphes MAXIMUM
- Sois DIRECT et CONCIS  
- Style conversationnel
- Cite 1-2 sources pour faits importants: (Source, Ann√©e)
- PAS de listes √† puces longues
- PAS de sections multiples

R√©ponds maintenant:"""

            # 2) Streaming Perplexity
            if not PERPLEXITY_API_KEY or not OPENAI_SDK_AVAILABLE:
                # Fallback non‚Äëbloquant
                yield "Le streaming n√©cessite une configuration PERPLEXITY_API_KEY et le SDK OpenAI.\n"
                yield "[DONE]"
                return

            selected_model = get_model_for_task("chat")
            client = OpenAI(api_key=PERPLEXITY_API_KEY, base_url=PERPLEXITY_BASE_URL, timeout=300.0)
            stream = client.chat.completions.create(
                model=selected_model,  # Mod√®le dynamique
                messages=[
                    {"role": "system", "content": f"Assistant sp√©cialis√© {business_context}. Utilise les documents fournis en priorit√©."},
                    {"role": "user", "content": chat_prompt}
                ],
                temperature=0.1,  # R√©duit pour plus de pr√©cision
                max_tokens=1500,
                stream=True,
            )

            for event in stream:
                try:
                    delta = event.choices[0].delta if hasattr(event.choices[0], "delta") else event.choices[0].get("delta", {})
                    content = getattr(delta, "content", None)
                    if content is None and isinstance(delta, dict):
                        content = delta.get("content")
                    if content:
                        yield content
                except Exception as inner:
                    logger.warning(f"Stream delta parse error: {inner}")
                    continue

            yield "[DONE]"
        except Exception as e:
            logger.error(f"Streaming error: {e}")
            yield "\n[STREAM_ERROR]"

    headers = {
        "Cache-Control": "no-cache",
        "X-Accel-Buffering": "no",  # Nginx: disable buffering
    }
    return StreamingResponse(token_generator(), media_type="text/plain", headers=headers)

@app.get("/test-perplexity")
async def test_perplexity():
    """Test de connectivit√© pour tous les mod√®les Sonar configur√©s"""
    try:
        if not PERPLEXITY_API_KEY:
            return {"status": "error", "message": "PERPLEXITY_API_KEY not configured"}
        
        client = OpenAI(
            api_key=PERPLEXITY_API_KEY,
            base_url=PERPLEXITY_BASE_URL,
            timeout=30.0
        )
        
        # Tester chaque mod√®le configur√©
        results = {}
        for task_type, model_name in PERPLEXITY_MODELS.items():
            try:
                response = client.chat.completions.create(
                    model=model_name,
                    messages=[{"role": "user", "content": "Test"}],
                    max_tokens=10
                )
                results[task_type] = {
                    "model": model_name,
                    "status": "‚úÖ OK",
                    "response": response.choices[0].message.content[:50]
                }
            except Exception as e:
                logger.error(f"Test Perplexity error: {e}")
                results[task_type] = {
                    "model": model_name,
                    "status": f"‚ùå Error: {str(e)[:100]}"
                }
        
        return {
            "status": "success", 
            "models_tested": results,
            "config": PERPLEXITY_MODELS
        }
        
    except Exception as e:
        return {"status": "error", "message": str(e)}

@app.get("/check-api-status")
async def check_api_status():
    """V√©rifie le statut de la cl√© API Perplexity et d√©tecte les erreurs de quota"""
    try:
        if not PERPLEXITY_API_KEY:
            return {
                "status": "error",
                "message": "PERPLEXITY_API_KEY not configured",
                "api_key_configured": False
            }
        
        client = OpenAI(
            api_key=PERPLEXITY_API_KEY,
            base_url=PERPLEXITY_BASE_URL,
            timeout=30.0
        )
        
        # Test avec le mod√®le chat (le moins co√ªteux)
        test_model = get_model_for_task("chat")
        
        try:
            response = client.chat.completions.create(
                model=test_model,
                messages=[{"role": "user", "content": "Hello"}],
                max_tokens=10
            )
            
            # Si on arrive ici, la cl√© fonctionne
            return {
                "status": "success",
                "api_key_configured": True,
                "api_key_valid": True,
                "test_model": test_model,
                "message": "‚úÖ Cl√© API valide et fonctionnelle",
                "note": "Pour v√©rifier votre quota exact, consultez https://www.perplexity.ai/settings/api"
            }
            
        except Exception as api_error:
            error_str = str(api_error).lower()
            
            # D√©tection des erreurs courantes
            if "401" in error_str or "unauthorized" in error_str:
                return {
                    "status": "error",
                    "api_key_configured": True,
                    "api_key_valid": False,
                    "error_type": "unauthorized",
                    "message": "‚ùå Cl√© API invalide ou expir√©e",
                    "suggestion": "V√©rifiez votre cl√© sur https://www.perplexity.ai/settings/api"
                }
            elif "429" in error_str or "rate limit" in error_str or "quota" in error_str:
                return {
                    "status": "error",
                    "api_key_configured": True,
                    "api_key_valid": True,
                    "error_type": "quota_exceeded",
                    "message": "‚ö†Ô∏è Quota d√©pass√© ou limite de taux atteinte",
                    "suggestion": "Consultez votre quota sur https://www.perplexity.ai/settings/api et ajoutez des cr√©dits si n√©cessaire"
                }
            elif "404" in error_str or "not found" in error_str:
                return {
                    "status": "error",
                    "api_key_configured": True,
                    "api_key_valid": True,
                    "error_type": "model_not_found",
                    "message": f"‚ùå Mod√®le '{test_model}' non trouv√©",
                    "suggestion": "V√©rifiez que le mod√®le est disponible avec votre plan sur https://www.perplexity.ai/settings/api"
                }
            else:
                return {
                    "status": "error",
                    "api_key_configured": True,
                    "api_key_valid": None,
                    "error_type": "unknown",
                    "message": f"‚ùå Erreur API: {str(api_error)[:200]}",
                    "suggestion": "Consultez https://www.perplexity.ai/settings/api pour v√©rifier votre compte"
                }
        
    except Exception as e:
        return {
            "status": "error",
            "message": str(e),
            "api_key_configured": bool(PERPLEXITY_API_KEY)
        }

@app.get("/diagnostics")
async def diagnostics():
    """Diagnostics complets du syst√®me"""
    
    diagnostics_result = {
        "timestamp": datetime.now().isoformat(),
        "service": "backend-intelligence-perplexity",
        "version": "2.0-perplexity-rag"
    }
    
    # Versions des libs cl√©s
    # Note: SDK OpenAI utilis√© uniquement pour compatibilit√© avec Perplexity API
    try:
        diagnostics_result["versions"] = {
            "python": os.getenv("PYTHON_VERSION", "unknown"),
            "openai_sdk": metadata.version("openai") if OPENAI_SDK_AVAILABLE else "not-installed",
            "httpx": metadata.version("httpx") if "httpx" in {d.metadata["Name"].lower() for d in map(lambda n: metadata.distribution(n), metadata.packages_distributions().keys()) if False} else metadata.version("httpx")
        }
    except Exception:
        try:
            diagnostics_result["versions"] = {
                "openai_sdk": metadata.version("openai") if OPENAI_SDK_AVAILABLE else "not-installed",
                "httpx": metadata.version("httpx")
            }
        except Exception as e:
            diagnostics_result["versions_error"] = str(e)

    # Proxies d'environnement (pour debug)
    diagnostics_result["env_proxies"] = {
        k: os.getenv(k)
        for k in ["HTTP_PROXY", "HTTPS_PROXY", "ALL_PROXY", "http_proxy", "https_proxy", "all_proxy"]
        if os.getenv(k)
    }

    # Test Perplexity
    try:
        if PERPLEXITY_API_KEY:
            client = OpenAI(
                api_key=PERPLEXITY_API_KEY,
                base_url=PERPLEXITY_BASE_URL,
                timeout=300.0
            )
            # Test avec le mod√®le chat par d√©faut
            test_model = get_model_for_task("chat")
            test_response = client.chat.completions.create(
                model=test_model,
                messages=[{"role": "user", "content": "test"}],
                max_tokens=5
            )
            diagnostics_result["perplexity"] = {
                "status": "‚úÖ Functional", 
                "models": PERPLEXITY_MODELS,
                "test_model": test_model
            }
        else:
            diagnostics_result["perplexity"] = {"status": "‚ùå Not configured", "models": None}
    except Exception as e:
        diagnostics_result["perplexity"] = {
            "status": f"‚ùå Error: {str(e)[:100]}", 
            "models": PERPLEXITY_MODELS
        }
    
    # Test Vector Service
    try:
        test_docs = search_documents_safe("test", top_k=1)
        diagnostics_result["vector_service"] = {
            "status": "‚úÖ Accessible" if len(test_docs) >= 0 else "‚ö†Ô∏è No results",
            "url": VECTOR_SERVICE_URL,
            "test_results": len(test_docs)
        }
    except Exception as e:
        diagnostics_result["vector_service"] = {"status": f"‚ùå Error: {str(e)[:100]}", "url": VECTOR_SERVICE_URL}
    
    # Test Business Types
    try:
        business_types = get_available_business_types()
        diagnostics_result["business_types"] = {"status": "‚úÖ Available", "count": len(business_types), "types": business_types}
    except Exception as e:
        diagnostics_result["business_types"] = {"status": f"‚ùå Error: {str(e)[:100]}"}
    
    return diagnostics_result

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8006)