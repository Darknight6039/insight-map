# üöÄ Guide de D√©marrage Rapide - Perplexity AI

## ‚úÖ Changements Effectu√©s

Votre syst√®me Insight MVP a √©t√© migr√© avec succ√®s de l'API OpenAI vers l'API Perplexity AI !

### Fichiers Modifi√©s

1. **`backend-service/app/main.py`** ‚úì
   - Remplac√© OpenAI par Perplexity
   - Ajout√© support RAG interne prioritaire
   - Nouveaux endpoints : `/test-perplexity`, `/diagnostics`

2. **`rag-service/app/main.py`** ‚úì
   - Migration vers Perplexity AI
   - Conservation des 5 types d'analyses
   - RAG hybride (documents internes + web)

3. **`env.example`** ‚úì
   - Nouvelles variables Perplexity
   - Documentation des mod√®les disponibles

4. **Votre fichier `.env`** ‚ö†Ô∏è
   - La cl√© API est d√©j√† configur√©e
   - **IMPORTANT** : Ce fichier est ignor√© par git (.gitignore)

## üîß D√©marrage Rapide

### √âtape 1 : V√©rifier la Configuration

Votre cl√© API Perplexity est d√©j√† configur√©e :

```bash
# V√©rifier que le fichier .env existe et contient la cl√©
cat .env | grep PERPLEXITY_API_KEY
```

Vous devriez voir :
```
PERPLEXITY_API_KEY=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
```

### √âtape 2 : D√©marrer les Services

```bash
# Si vous utilisez docker-compose
docker-compose down
docker-compose up -d --build

# V√©rifier que les services sont d√©marr√©s
docker-compose ps
```

### √âtape 3 : Tester l'Int√©gration

```bash
# Utiliser le script de test fourni
./test_perplexity_integration.sh
```

Ou manuellement :

```bash
# Test 1: Health check backend
curl http://localhost:8006/health

# Test 2: Test Perplexity direct
curl http://localhost:8006/test-perplexity

# Test 3: Chat simple avec RAG
curl -X POST http://localhost:8006/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Quelles sont les tendances du march√© bancaire?",
    "business_type": "finance_banque"
  }'
```

## üéØ Points Cl√©s de la Migration

### Ce qui a chang√©

| Avant (OpenAI) | Apr√®s (Perplexity) |
|----------------|-------------------|
| API OpenAI uniquement | Perplexity avec recherche web |
| Mod√®le : gpt-4o-mini | Mod√®le : llama-3.1-sonar-large-128k-online |
| Pas de recherche web | Enrichissement web automatique |
| `/test-openai` | `/test-perplexity` |

### Ce qui reste identique

‚úÖ **Tous les endpoints existants** fonctionnent exactement de la m√™me mani√®re  
‚úÖ **Le syst√®me RAG** continue de prioriser vos documents internes  
‚úÖ **Les citations APA** sont toujours g√©n√©r√©es  
‚úÖ **Les 5 types d'analyses** sont conserv√©s  

## üìä Fonctionnement du RAG Hybride

```
Votre Question
      ‚Üì
1. Recherche dans vos documents internes (Qdrant)
      ‚Üì
2. Les meilleurs passages sont extraits
      ‚Üì
3. Perplexity re√ßoit :
   - Vos documents (PRIORIT√â 1) ‚úì
   - Instruction de chercher sur le web si besoin (PRIORIT√â 2)
      ‚Üì
4. R√©ponse enrichie avec :
   - Citations de vos docs [R√©f. 1], [R√©f. 2]...
   - Donn√©es web r√©centes (si pertinent)
```

## üß™ Exemples de Test

### Test 1 : Chat Simple

```bash
curl -X POST http://localhost:8006/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Analyse les risques du secteur fintech",
    "business_type": "finance_banque"
  }' | jq '.'
```

### Test 2 : Analyse Compl√®te

```bash
curl -X POST http://localhost:8006/extended-analysis \
  -H "Content-Type: application/json" \
  -d '{
    "business_type": "tech_digital",
    "analysis_type": "digital_transformation",
    "query": "Transformation digitale des banques",
    "title": "Banking Digital 2024"
  }' | jq '.metadata'
```

### Test 3 : Veille Technologique

```bash
curl -X POST http://localhost:8003/tech_watch \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Intelligence artificielle dans le trading",
    "title": "AI Trading 2024",
    "top_k": 8
  }' | jq '.content[0:500]'
```

## ‚öôÔ∏è Configuration Avanc√©e

### Changer de Mod√®le Perplexity

√âditez votre `.env` :

```bash
# Pour un mod√®le plus √©conomique
PERPLEXITY_MODEL=llama-3.1-sonar-small-128k-online

# Pour le mod√®le le plus puissant
PERPLEXITY_MODEL=llama-3.1-sonar-huge-128k-online
```

Puis red√©marrez :
```bash
docker-compose restart backend-service rag-service
```

### Ajuster les Param√®tres RAG

Dans `backend-service/app/main.py`, ligne ~520 :

```python
response = client.chat.completions.create(
    model=PERPLEXITY_MODEL,
    messages=[...],
    temperature=0.3,      # Ajustez entre 0.0 (pr√©cis) et 1.0 (cr√©atif)
    max_tokens=8000       # Longueur max de la r√©ponse
)
```

## üêõ D√©pannage Rapide

### Erreur : "PERPLEXITY_API_KEY not configured"

```bash
# V√©rifier que la variable est bien dans .env
grep PERPLEXITY .env

# Red√©marrer les services
docker-compose restart
```

### Erreur : "Connection refused"

```bash
# V√©rifier que les services tournent
docker-compose ps

# Red√©marrer si n√©cessaire
docker-compose up -d
```

### Les r√©ponses ne citent pas mes documents

```bash
# V√©rifier que les documents sont index√©s
curl http://localhost:8001/documents

# Tester la recherche vectorielle
curl -X POST http://localhost:8002/search \
  -H "Content-Type: application/json" \
  -d '{"query": "test", "top_k": 5}'
```

### Voir les Logs

```bash
# Tous les services
docker-compose logs -f

# Backend uniquement
docker-compose logs -f backend-service

# RAG service uniquement
docker-compose logs -f rag-service
```

## üìö Documentation Compl√®te

Pour plus de d√©tails, consultez :
- **`PERPLEXITY_MIGRATION.md`** - Documentation compl√®te de la migration
- **`README.md`** - Documentation g√©n√©rale du projet

## üí° Avantages de Perplexity

1. **üîç Recherche Web Int√©gr√©e** : Enrichit automatiquement avec des donn√©es r√©centes
2. **üìö RAG Prioritaire** : Vos documents internes restent la source principale
3. **‚ö° Performance** : Mod√®les LLaMA 3.1 tr√®s performants
4. **üí∞ Co√ªt** : G√©n√©ralement moins cher qu'OpenAI pour des r√©sultats comparables
5. **üåê Contexte Long** : 128k tokens de contexte

## üöÄ Prochaines √âtapes

1. ‚úÖ Testez les endpoints : `./test_perplexity_integration.sh`
2. ‚úÖ V√©rifiez la qualit√© des r√©ponses
3. ‚úÖ Ajustez les param√®tres si n√©cessaire (temp√©rature, max_tokens)
4. ‚úÖ Indexez vos documents : voir `scripts/ingest_pdfs.py`
5. ‚úÖ Utilisez l'interface frontend (si disponible)

## ‚ùì Questions Fr√©quentes

**Q: Puis-je revenir √† OpenAI ?**  
R: Oui, il suffit de restaurer les fichiers depuis git et reconfigurer OPENAI_API_KEY

**Q: Perplexity va-t-il chercher sur le web pour chaque requ√™te ?**  
R: Non, il utilise d'abord vos documents internes. Le web est un compl√©ment.

**Q: Combien co√ªte Perplexity ?**  
R: ~$0.001-0.005 par requ√™te selon le mod√®le. V√©rifiez sur perplexity.ai

**Q: Les mod√®les sont-ils compatibles ?**  
R: Oui, l'API Perplexity est compatible avec OpenAI SDK.

---

**F√©licitations ! üéâ** Votre syst√®me est maintenant propuls√© par Perplexity AI avec RAG hybride.

Pour toute question : consultez les logs ou la documentation compl√®te.

