"""
RAG Service Standardis√© - Structure uniforme pour tous les rapports professionnels
"""

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Dict, Optional
import os
import requests
from datetime import datetime
from loguru import logger

app = FastAPI(title="RAG Service Standardis√©", description="RAG avec structure rapport standardis√©e")

# Configuration
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
VECTOR_SERVICE_URL = "http://vector-service:8002"

# Mod√®les
class AnalysisRequest(BaseModel):
    query: str
    title: Optional[str] = None

class AnalysisResponse(BaseModel):
    analysis_type: str
    title: str
    content: str
    sources: List[Dict]
    metadata: Dict
    timestamp: str

def search_documents(query: str, top_k: int = 8) -> List[Dict]:
    """Recherche vectorielle avec fallback"""
    try:
        response = requests.post(
            f"{VECTOR_SERVICE_URL}/search",
            json={"query": query, "top_k": top_k},
            timeout=10
        )
        
        if response.status_code == 200:
            result = response.json()
            return result.get("results", [])
        else:
            logger.warning(f"Vector search failed: {response.status_code}")
            return []
            
    except Exception as e:
        logger.error(f"Vector search error: {e}")
        return []

def create_standardized_prompt(analysis_type: str, query: str, documents: List[Dict]) -> str:
    """Cr√©e un prompt standardis√© selon le pattern d√©fini"""
    
    # Contexte des documents
    context = ""
    if documents:
        context = "## DOCUMENTS DE R√âF√âRENCE\n\n"
        for i, doc in enumerate(documents[:5], 1):
            doc_text = doc.get('text', '')[:300]
            score = doc.get('score', 0)
            context += f"**[R√©f. {i}]** (Score: {score:.3f}):\n{doc_text}...\n\n"
    
    # Sp√©cialisations par type d'analyse
    analysis_specifics = {
        "synthese_executive": {
            "focus": "synth√®se strat√©gique et recommandations ex√©cutives",
            "key_sections": "opportunit√©s strat√©giques, risques majeurs, recommandations prioritaires"
        },
        "analyse_concurrentielle": {
            "focus": "paysage concurrentiel et positionnements strat√©giques", 
            "key_sections": "parts de march√©, forces/faiblesses concurrentielles, benchmarking"
        },
        "veille_technologique": {
            "focus": "innovations technologiques et tendances √©mergentes",
            "key_sections": "technologies disruptives, adoption market, roadmap innovation"
        },
        "analyse_risques": {
            "focus": "identification et mitigation des risques",
            "key_sections": "cartographie risques, probabilit√©/impact, mesures pr√©ventives"
        },
        "etude_marche": {
            "focus": "dynamiques de march√© et projections business",
            "key_sections": "taille de march√©, segments clients, projections croissance"
        }
    }
    
    specific = analysis_specifics.get(analysis_type, analysis_specifics["synthese_executive"])
    
    # Prompt standardis√© uniforme
    standardized_prompt = f"""
Tu es un consultant senior de McKinsey/BCG. G√©n√®re un rapport professionnel bas√© EXCLUSIVEMENT sur les documents fournis.

{context}

DEMANDE D'ANALYSE: {query}
FOCUS SP√âCIALIS√â: {specific['focus']}

STRUCTURE OBLIGATOIRE √Ä RESPECTER EXACTEMENT:

# RAPPORT PROFESSIONNEL - {analysis_type.replace('_', ' ').upper()}

## üéØ EXECUTIVE SUMMARY
### Key Findings
[3-4 d√©couvertes majeures avec donn√©es chiffr√©es des documents [R√©f. X]]

### Recommandations Prioritaires  
[2-3 actions strat√©giques imm√©diates avec justifications]

### M√©triques Cl√©s
[Indicateurs de performance avec benchmarks tir√©s des sources]

---

## üìä MARKET OVERVIEW
### Taille et Croissance
[Dimensionnement du march√© avec chiffres pr√©cis [R√©f. X]]

### Segmentation
[Segments principaux et caract√©ristiques [R√©f. X]]

### Tendances Macro
[Forces macro-√©conomiques influen√ßant le secteur [R√©f. X]]

---

## ‚öîÔ∏è COMPETITIVE LANDSCAPE  
### Leaders du March√©
[Acteurs dominants avec parts de march√© [R√©f. X]]

### Positionnements Strat√©giques
[Diff√©renciation et strat√©gies concurrentielles [R√©f. X]]

### Analyse Forces/Faiblesses
[Avantages concurrentiels et vuln√©rabilit√©s [R√©f. X]]

---

## üí° KEY INSIGHTS
### D√©couvertes Majeures
[{specific['key_sections']} bas√©s sur les documents [R√©f. X]]

### Patterns Identifi√©s  
[Tendances et corr√©lations importantes [R√©f. X]]

### Opportunit√©s Strat√©giques
[Gaps de march√© et potentiel de croissance [R√©f. X]]

---

## ‚ö° RECOMMENDATIONS
### Actions Court Terme (0-6 mois)
[3 initiatives imm√©diates avec ROI attendu]

### Initiatives Moyen Terme (6-18 mois)
[2 projets structurants avec jalons]

### Vision Long Terme (+18 mois)
[1 transformation majeure avec vision 3-5 ans]

---

## üìö APPENDIX
### M√©thodologie
[Approche d'analyse utilis√©e]

### Sources Principales
[Documents de r√©f√©rence avec scores de pertinence]

### Limitations
[Biais potentiels et donn√©es manquantes]

CRIT√àRES QUALIT√â:
- Utilise UNIQUEMENT les donn√©es des documents fournis
- Cite [R√©f. X] pour chaque affirmation chiffr√©e
- Structure rigoureusement respect√©e
- Style professionnel consultant senior
- Donn√©es quantifi√©es prioritaires
- Recommandations actionables et mesurables
"""
    
    return standardized_prompt

def call_openai_standardized(prompt: str) -> str:
    """Appel OpenAI avec syst√®me prompt renforc√©"""
    try:
        if not OPENAI_API_KEY or OPENAI_API_KEY == "your_openai_api_key_here":
            return "‚ö†Ô∏è Configuration OpenAI requise pour analyses avec vos documents."
        
        from openai import OpenAI
        client = OpenAI(api_key=OPENAI_API_KEY)
        
        # Syst√®me prompt renforc√© pour structure standardis√©e
        system_prompt = """Tu es un consultant expert McKinsey/BCG sp√©cialis√© dans la g√©n√©ration de rapports professionnels structur√©s.

IMP√âRATIFS ABSOLUS:
1. RESPECTER EXACTEMENT la structure fournie dans le prompt
2. UTILISER UNIQUEMENT les informations des documents de r√©f√©rence
3. CITER syst√©matiquement [R√©f. X] pour chaque donn√©e
4. QUANTIFIER toutes les affirmations avec des chiffres pr√©cis
5. FORMATER en markdown professionnel avec √©mojis de section
6. RESTER FACTUEL et √©viter les g√©n√©ralit√©s

QUALIT√â ATTENDUE:
- Niveau consultant senior McKinsey/BCG
- Donn√©es 100% issues des documents fournis
- Structure rigoureusement respect√©e
- Recommandations actionables et mesurables
- Style professionnel et concis"""
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,  # Plus d√©terministe pour structure
            max_tokens=4000
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        logger.error(f"OpenAI error: {e}")
        return f"Erreur d'analyse: {str(e)}"

def format_sources_standardized(documents: List[Dict]) -> str:
    """Formate les sources de mani√®re standardis√©e"""
    if not documents:
        return ""
    
    sources = "\n\n---\n## üìã R√âF√âRENCES DOCUMENTAIRES\n\n"
    for i, doc in enumerate(documents[:5], 1):
        text_preview = doc.get('text', '')[:150]
        score = doc.get('score', 0)
        doc_id = doc.get('doc_id', 'N/A')
        sources += f"**[R√©f. {i}]** Document {doc_id} | Score: {score:.3f}\n"
        sources += f"*Extrait:* \"{text_preview}...\"\n\n"
    
    return sources

async def generate_standardized_analysis(analysis_type: str, query: str, title: str = None) -> AnalysisResponse:
    """G√©n√®re analyse avec structure standardis√©e"""
    try:
        # 1. Recherche vectorielle
        logger.info(f"Recherche vectorielle pour: {query}")
        documents = search_documents(query, top_k=8)
        
        # 2. Cr√©ation du prompt standardis√©
        prompt = create_standardized_prompt(analysis_type, query, documents)
        
        # 3. Appel OpenAI avec syst√®me renforc√©
        content = call_openai_standardized(prompt)
        
        # 4. Ajout des sources standardis√©es
        if documents and content:
            content += format_sources_standardized(documents)
        
        return AnalysisResponse(
            analysis_type=analysis_type,
            title=title or f"Rapport {analysis_type.replace('_', ' ').title()}",
            content=content,
            sources=[{
                "doc_id": d.get("doc_id"),
                "score": d.get("score"),
                "text": d.get("text", "")[:200]
            } for d in documents],
            metadata={
                "query": query,
                "documents_found": len(documents),
                "vector_search": "active" if documents else "no_results",
                "model": "gpt-4o-mini",
                "structure": "standardized_v1",
                "quality_level": "mckinsey_bcg"
            },
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as e:
        logger.error(f"Error in standardized analysis: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Endpoints avec structure standardis√©e
@app.get("/health")
def health():
    return {"status": "healthy", "service": "rag-standardized", "structure": "mckinsey_bcg_v1"}

@app.post("/synthesize", response_model=AnalysisResponse)
async def synthesize(request: AnalysisRequest):
    """Synth√®se ex√©cutive standardis√©e"""
    return await generate_standardized_analysis("synthese_executive", request.query, request.title)

@app.post("/analyze_competition", response_model=AnalysisResponse)
async def analyze_competition(request: AnalysisRequest):
    """Analyse concurrentielle standardis√©e"""
    return await generate_standardized_analysis("analyse_concurrentielle", request.query, request.title)

@app.post("/tech_watch", response_model=AnalysisResponse)
async def tech_watch(request: AnalysisRequest):
    """Veille technologique standardis√©e"""
    return await generate_standardized_analysis("veille_technologique", request.query, request.title)

@app.post("/risk_analysis", response_model=AnalysisResponse)
async def risk_analysis(request: AnalysisRequest):
    """Analyse des risques standardis√©e"""
    return await generate_standardized_analysis("analyse_risques", request.query, request.title)

@app.post("/market_study", response_model=AnalysisResponse)
async def market_study(request: AnalysisRequest):
    """√âtude de march√© standardis√©e"""
    return await generate_standardized_analysis("etude_marche", request.query, request.title)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8003)
